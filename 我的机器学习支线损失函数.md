# ***我的机器学习支线损失函数***

[toc]



## **语义分割**

**语义分割结合了图像分类、目标检测和图像分割，通过一定的方法将图像分割成具有一定语义含义的区域块，并识别出每个区域块的语义类别，实现从底层到高层的语义推理过程，最终得到一幅具有逐像素语义标注的分割图像。设计损失函数想要达到的目标是损失与梯度同步变化，求导自变量定义为神经网络的最后一层带权重层的输出。当学习率恒定时，希望当预测结果远离真实值时，损失大，梯度大；当预测结果靠近真实值时，损失小，梯度小**



### **交叉熵损失**

**最常用损失函数是像素级别的交叉熵损失 *(cross entropy loss，ce)*，逐个检查每个像素，将对每个像素类别的预测结果（概率分布向量）与热编码标签向量进行比较**

**假设我们需要对每个像素的预测类别有 $5$ 个，则预测的概率分布向量长度也为 $5$ 维**

<img src="Markdown%E5%9B%BE%E5%BA%8A/%E6%88%91%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%94%AF%E7%BA%BF%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/640-20220524102921096.jpeg" alt="图片" style="zoom:50%;" />

**对应的每个像素损失函数**
$$
\pmb{loss_{pixel}}=-\sum_{class}y_{true}^{class}log(y_{pred}^{class})
$$
**令 $y_{pred}=softmax(x)$ 那么回传的梯度为 $\frac{d(loss_{ce})}{dx}=\sum_{class}y_{true}^{class}(y_{pred}^{class}-1)$ 正比于每个类别误差求和的均值，因此优化过程中损失小时梯度小**

**整个图像的损失就是全部像素损失的平均值**
$$
\pmb{loss_{ce}}=\frac{1}{n}\sum_{pixel=1}^{n}loss_{pixel}
$$
**特别注意 *(binary entropy loss，bce)* 是针对只有两个类别的情况的损失函数**
$$
\pmb{loss_{bce}}=-y_{true}log(y_{pred})-(1-y_{true})log(1-y_{pred})
$$
**如果 $y_{pred}=sigmoid(x)$ 那么回传的梯度为 $\frac{d(loss_{bce})}{dx}=y_{pred}-y_{true}$ 正比于误差，因此优化过程中损失小时梯度小**



### **Weighted Loss**

**交叉熵损失会分别评估每个像素的类别预测，然后对所有像素的损失进行平均，因此实质上是在对图像中的每个像素进行平等地学习。如果多个类在图像中的分布不均衡，那么这可能导致训练过程由像素数量多的类所主导，即模型会主要学习数量多的类别样本的特征，并且学习出来的模型会更偏向将像素预测为该类别**

**全卷积神经网络 *FCN* 与 *U* 型神经网路 *U-Net* 论文中对输出概率分布向量中的每个值进行加权，使得模型更加关注数量较少的样本，以缓解图像中存在的类别不均衡问题**

**例如，二分类中正负样本比例为 $1:99$，此时模型将所有样本都预测为负样本，那么准确率仍有 $99\%$，然而实际上没有意义**

**为了平衡这个差距，就对正样本和负样本的损失赋予不同的权重，带权重的二分类损失函数 *weighted loss***
$$
\pmb{loss_{wieghted}}=-pos_{wieghted}\times y_{true}log(y_{pred})-(1-y_{true})log(1-y_{pred})\\
\pmb{pos_{wieghted}=\frac{neg_{num}}{pos_{num}}}
$$
**令 $y_{pred}=sigmoid(x)$ 那么回传的梯度为 $\frac{d(loss_{wieghted})}{dx}=(1-y_{true})y_{pred}-pos_{wieghted}\times y_{true}(1-y_{pred})$ 正比于误差，且正样本则为 $pos_{wieghted}(y_{pred}-1)$ 被抑制，负样本则为 $-y_{pred}$ 相对增强，因此优化过程中损失小时梯度小，且放大了负样本的优化效果**



### **Focal Loss**

**有时不仅需要针对不同类别的像素数量的不均衡改进，还需要将像素分为难学习和容易学习这两种样本，对于容易学习的样本模型可以很轻松地预测正确，而模型只要将大量容易学习的样本预测正确，*loss* 就会减小很多，从而导致模型无法顾及难学习的样本，所以要让模型更加关注难学习的样本**

**对于难易程度不同的学习样本可赋予不同的权重调整**
$$
-(1-y_{pred})^{\gamma}\times y_{true}log(y_{pred})-y_{pred}^{\gamma}(1-y_{true})\times log(1-y_{pred})\\
default\;\gamma=2
$$
**例如，预测一个正样本，预测结果为 $0.95$ 是一个容易学习的样本，有 $(1-0.95)^2=0.0025$ 损失直接减少为原来的 $1\over400$，预测结果为 $0.5$ 是一个难学习的样本，有 $(1-0.5)^2=0.25$，损失减小为原来的 $1\over4$，相对减小的程度小很多，总体上更多的考虑到了难学习样本，因此模型更加专注学习难学习的样本**

**可得考虑正负样本不均衡与难易程度的 *focal loss***
$$
\pmb{loss_{focal}}=-\alpha(1-y_{pred})^{\gamma}\times y_{true}log(y_{pred})-(1-\alpha)y_{pred}^{\gamma}(1-y_{true})\times log(1-y_{pred})\\
\pmb{default\;\gamma=2}
$$
**梯度性质于 *Weighted Loss* 类似**



### **Soft Dice Loss**

**常用的损失函数还有基于 $Dice$ 系数的损失函数 *(soft dice loss，sd)* 其系数实质是两个样本之间重叠的度量，范围为 $0～1$，其中 $1$ 表示完全重叠**
$$
Dice=\frac{2|A\cap B|}{|A|+|B|}=\frac{2TP}{2TP+FP+FN}
$$
**$|A\cap B|$ 代表集合 $A$ 和 $B$ 之间的公共元素，并且 $|A|$ 与 $|B|$ 分别代表集合 $A$ 和 $B$ 的元素数量，分子乘 $2$ 保证取值范围在 $[0,1]$，$|A\cap B|$ 为预测掩码和标签掩码之间的逐元素乘法，然后对结果矩阵求和**

<img src="Markdown%E5%9B%BE%E5%BA%8A/%E6%88%91%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%94%AF%E7%BA%BF%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/640.jpeg" alt="图片" style="zoom:50%;" />

**$Dice$ 系数中 $TP$ 为真阳性样本 $FP$ 为假阳性样本 $FN$ 为假阴性样本，而 $precision=\frac{TP}{TP+FP}$，$recall=\frac{TP}{TP+FN}$，可知 $Dice$ 包涵了两部分的意义**

**对于神经网络的输出，分子与我们的预测和标签之间的共同激活有关，而分母分别与每个掩码中的激活数量有关，具有根据标签掩码的尺寸对损失进行归一化的效果**

<img src="Markdown%E5%9B%BE%E5%BA%8A/%E6%88%91%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%94%AF%E7%BA%BF%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/640-20220524102921043.jpeg" alt="图片" style="zoom: 50%;" />

**对每个类别都计算 $1-Dice$ 后求和取平均得到最后的 *soft dice loss***
$$
\pmb{loss_{sd}}=\frac{1}{n}\sum_{class=1}^{n}\left\{1-\frac{2\sum_{piexl}(y_{true}y_{pred})}{\sum_{piexl}(y_{true}+y_{pred})}\right\}
$$
**如果是二分类则令 $y_{pred}=sigmoid(x)$ 那么回传的梯度为**
$$
\frac{d(loss_{sd}^{pixel})}{dy^{pixel}}=\frac{1}{2}\sum_{class=1}^{2}\left\{\frac{2[y_{true}^{pixel}(y_{true}^{pixel}+y_{pred}^{pixel})-y_{true}^{pixel}y_{pred}^{pixel}]}{(y_{true}^{pixel}+y_{pred}^{pixel})^2}\right\}=\frac{1}{2}\sum_{class=1}^{2}
\begin{cases}
0&,y_{true}^{pixel}=0\\
\frac{-2}{(1+y_{pred}^{pixel})^2}&,y_{true}^{pixel}=1
\end{cases}
$$

$$
\frac{d(loss_{sd}^{pixel})}{dx^{pixel}}=\frac{d(loss_{sd}^{pixel})}{dy^{pixel}}\times\frac{e^{-x^{pixel}}}{(e^{-x^{pixel}}+1)^2}
$$

<img src="Markdown%E5%9B%BE%E5%BA%8A/%E6%88%91%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%94%AF%E7%BA%BF%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/output-3396439.svg" alt="output" style="zoom: 67%;" />

**随着 $x^{pixel}$ 增大，损失（蓝色）趋向零梯度（红色）趋向零，随着 $x^{pixel}$ 减小，损失趋于一梯度趋向零（类似均方误差 *(mse)* 不论预测接近真实值或是接近错误值，梯度都很小）**



### **Soft IoU Loss**

**计算 $Dice$ 系数的公式也可以表示为**
$$
Dice=\frac{2TP}{2TP+FP+FN}
$$


**$IoU$ 的计算公式和这个很像，区别仅只计算一次 $TP$** 
$$
IoU=\frac{TP}{TP+FP+FN}=\frac{|A\cap B|}{|A|+|B|-|A\cap B|}
$$
**对于每个类别的 *mask* 都计算 $1-IoU$ 最后求和取平均得到基于 $IoU$ 系数的损失函数 *(soft iou loss，si)* 为**
$$
\pmb{loss_{si}}=\frac{1}{n}\sum_{class=1}^{n}\left\{1-\frac{\sum_{piexl}(y_{true}y_{pred})}{\sum_{piexl}(y_{true}+y_{pred}-y_{true}y_{pred})}\right\}
$$
**梯度性质于 *soft dice loss* 类似**



## **小结**

**交叉熵损失把每个像素都当作一个独立样本进行预测，而 *soft dice loss* 与 *soft iou loss* 则以更整体的方式来看待最终的预测输出，两类损失是针对不同情况，各有优点和缺点，在实际应用中，可以同时使用这两类损失来进行互补**

**参考**

- [语义分割中的 loss function 最全面汇总](https://mp.weixin.qq.com/s/GkiV_KMWLcxiFnqFavtuwA)
- [An overview of semantic image segmentation](https://www.jeremyjordan.me/semantic-segmentation)
- [Loss Functions for Medical Image Segmentation](https://medium.com/@junma11/loss-functions-for-medical-image-segmentation-a-taxonomy-cefa5292eec0)
- [Losses for Image Segmentation](https://lars76.github.io/neural-networks/object-detection/losses-for-segmentation)