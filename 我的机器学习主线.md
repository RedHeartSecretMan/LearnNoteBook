# ***我的机器学习主线***

[toc]



## **绪论**

**命题是逻辑的起点，命题中一类是通过无数的实验与经验验证，被广泛承认正确的数学公理与物理定律；另一类是基于这些公理与定律的逻辑推论即定理。公理与定律有适用范围，不可被证明，通过归纳法得出，通常是父命题，定理可以被证明，通过演绎法得出，通常是子命题，这些命题构建了机器学习**



### **前言**

**机器学习是什么？越是简单的概念越是难以定义。比如有人认为机器学习问题事实上是一个优化问题，有人认为是机器学习是一个编程概念，也有人认为现阶段的机器学习是统计推断。Tom Mitchell 认为每个机器学习都可以精准地定义为「任务T」、「训练过程E」和「模型表现P」，机器学习的过程则可以拆解为「为了实现任务T」，我们「通过训练过程E」，逐步「提高表现P」的一个过程**



### **思想实验**

**假如世界上还没有机器学习，我们希望机器能够复刻人类与生俱来的学习能力，我们应该如何从零开始实现它**

- **白盒思路**

  >  *把问题掰开了揉碎了，梳理清晰问题的内部结构，从根子上建构完整的理解*

- **黑盒思路**

  > *不纠结问题的内部结构，不要求完全弄懂问题的来龙去脉，只需通过它与周围其他事物间的关系确定它的边界，清晰的把握它的作用和意义* 

- **定义黑盒的学习**

  > *学习绝不是简易记忆而是基于记忆作出<font face="楷体" color=red> 预判 </font>，学习经历过的事情让我们对没有经历的事情作出准确的预判，学习的内容虽然都是已知，但是学习后的经验却可以推广到未知*



### **如何工作**

**通过演绎、归纳和演化实现预判**

- **演绎**

  > *演绎是绝对的理性。最典型演绎是数学，首先做好定义、公理和逻辑规则等前置条件，然后基于定义与公理通过逻辑规则进行推理，最后建立一个庞大知识体系，其中定义、公理和逻辑规则是已知推理建立的庞大知识体系是未知。演绎的学习方法要求我们相信绝对的理性，其背后是柏拉图视角下的世界观，认为存在一个永恒的一致的真理，通过理性我们可以拨云见雾掌握真理，基于演绎的符号主义是实现人工智能最早的流派，然而现阶段仅仅依靠预设的前置条件进行演绎却连自然语言处理任务也难以实现*

- **归纳**

  > *归纳是理性和经验的结合。现阶段实现自然语言处理任务的主流就是使用数学模型加数据的方法，数学模型就是理性，数据就是经验代表既定的事实，事实背后的规律需要寻找，可以利用抽象能力把数据的有效特征提取出来，通过理性建立特征之间的联系寻找背后的规律。归纳背后是承认这个世界不是绝对理性的而是有模糊的不确定的部分，但是相信这部分间具有规律。基于归纳的连接主义实现人工智能时广泛使用的神经网络就是定义数学模型并且提供数据从中总结规律*

  > *值得注意的是，通过演绎得出的结论通常是不会出错而通过归纳得出的结论则可能因为数据量不够导致得出的结论出错，直观上给人的感觉就是演绎更可靠，归纳不可靠，然而归纳不可靠却成为了学习过程中的优势，归纳内秉的模糊与不确定有助于解决自然语言处理问题，自然语言是人类社会发展过程中自然产生的语言，是人类智慧和文明的产物，人类并不是完全理性的动物，因此自然语言背后很难说有一个永恒的一致的真理* 

  > *当下机器学习的主流的方法通常是归纳，例如通过最小间隔的支持向量机与通过梯度下降的神经网络*

- **演化**

  > *演化是纯粹的经验。演化是没有方向的变化，可以是由简单到复杂的进化，也可以是由复杂到简单的退化。演化的主要机制是生物的可遗传变异，以及生物对环境的适应和物种间的竞争。基于演化的行为主义中典型学习算法有遗传算法，同样具有从已知到未知的过程，一代一代的变异与反馈就是已知，而下一代的表现就是未知*

  > *值得注意的是，演化不会主动的利用理性从已有的经验中总结规律，演化的核心是实践，吃一堑长一智通过不断的迭代将有效的经验一条条的记录到一个巨型列表中，这个过程没有抽象没有推理也不需要理性，但是仍然可以跨越从已知到未知的边界，仍然算是学习，理性是人类具有的高级思维，细菌与植物不具有但是仍然可以通过演化的方式进行学习*

- **演绎、归纳和演化分别对应符号主义、连接主义和行为主义三个流派的理念**



## **概率论**

**概率论研究随机变量的性质，比如已知随机变量满足正态分布，通过数理统计的方法推断随机变量的期望（均值随样本趋于无穷的极限）及其方差**

**支持向量机与神经网络的理论基础是大数定律和中心极限定理，大数定律研究一系列随机变量 $X_1,X_2,\cdots,X_n$  的样本均值 $\overline{X}_n = \frac{1}{n}\sum^n_{k=1}X_k$ 是否会收敛于期望 $E(X_n)$ 也称总体均值；中心极限定理研究一系列随机变量 $\{X_n\}$ 不论服从何种分布，其均值 $\overline{X}_n$ 在随机变量的数量 $n$ 足够大时，$\overline{X}_n$ 总会趋于正态分布**



### **大数定律**

**大数定律分为强大数定律和弱大数定律，前者关于的独立性、异质性（同分布）和矩条件（均值与方差，在统计工作中描述集中趋势和离散程度的两个最重要的测度值）的约束条件强于后者。大数定律表明，随着样本数的增大，可以用样本均值来估计总体均值**

- **独立同分布**

  > *独立代表样本是独立的事件即实验中一个事件的发生不会影响到另一事件发生。例如 $A、B$ 是两个事件，满足 $P(A ∩ B) = P(AB) = P(A)P(B)$，则事件 $A$ 和 $B$ 相互独立。*
  >
  > *同分布意味所有样本中的属于相同的分布。分布即概率分布是事件概率的数学函数例如离散变量的概率质量函数 $p(x)$ 与连续变量的概率密度函数 $f(x)$ 或累积分布函数 $\Phi(x)$，根据「样本空间即观察到的随机现象的所有可能事件的集合」与「事件概率即样本空间的子集」使用数学语言描述随机现象*
  >
  > *在机器学习中通常假设数据独立同分布，得似然函数 $I(\Theta)$ 并取对数似然函数 $log(I(\Theta))$ 求极值，其中对数变换提高了效率因为计算机加法运算快于乘法，并且容易应用中心极限定理* 
  > $$
  > \begin{aligned}
  > &\mathrm{argmax}\;I(\Theta)=P(X_1,X_2,X_3,....X_n|\Theta)=P(X_1|\Theta)\ast P(X_2|\Theta)\ast ...\ast P(X_n|\Theta)\\
  > &\mathrm{argmax}\;log(I(\Theta))=log(P(X_1|\Theta)) + log(P(X_2|\Theta)) + ... + log(P(X_n|\Theta))
  > \end{aligned}
  > $$

- **均值与方差**

  > *均值是随机变量的算术平均值，方差是随机变量与其总体均值或样本均值的偏差的平方的算术平均值* 
  >
  > *离散的随机变量 $X$，概率质量函数为 $p(x)$​*
  > $$
  > \begin{aligned}
  > D(X)=&\sum_{i=1}^n p(x_i)\cdot(x_i - \sum_{i=1}^n (p(x_i)\cdot x_i))^2\\
  > =&E\{[X-E(X)]^2\}\\
  > =&E(X^2)-E(2XE(X))+E(X)^2\\
  > =&E(X^2)-2E(X)E(X)+E(X)^2\\
  > =&E(X^2)-E(X)^2
  > \end{aligned}
  > $$
  > *连续的随机变量 $X$，定义域为 $(a,b)$，概率密度函数为 $f(x)$*
  > $$
  > \begin{aligned}
  > D(X)=&\int^b_a(x-\mu)^2f(x)\,dx\\
  > =&\int^b_ax^2f(x)\,dx-\int^b_a2x\mu f(x)\,dx-\int^b_a\mu^2 f(x)\,dx\\
  > =&\int^b_ax^2f(x)\,dx-2\mu\int^b_ax f(x)\,dx-\mu^2\cdot1\\
  > =&\int^b_ax^2f(x)\,dx-2\mu\cdot\mu-\mu^2\\
  > =&\int^b_ax^2f(x)\,dx-\mu^2\\
  > =&E(X^2)-E(X)^2
  > \end{aligned}
  > $$
  > *随机变量的方差是随机变量的平方的期望与随机变量的期望的平方之和，随机变量的均值与方差不一定都存在* 
  > $$
  > \pmb{\text{存在均值}\not\Rightarrow\text{存在方差}}\\
  > \pmb{\text{存在方差}\Rightarrow\text{存在均值}}
  > $$
  > *如果多个随机变量不确定是否独立，则误差分析需考虑多个随机变量的总体误差即协方差* 
  > $$
  > \begin{aligned}
  > Cov(X,Y)=&E[(X-\mu)(Y-v)]\\
  > =&E(X\cdot Y)-\mu v
  > \end{aligned}
  > $$
  > *值得注意的是随机变量独立是协方差 $Cov(X,Y)=E(X)\cdot E(Y)-\mu v=0$ 的充分不必要条件，随机变量独立需要保证随机变量间既没有线性相关也没有非线性相关，随机变量的协方差为零仅代表没有线性相关性即 $\eta ={\frac {Cov(X,Y)}{\sqrt {D(X)\cdot D(Y)}}}=0$，即一系列随机变量 $X1,\cdots, Xn$ 有*
  > $$
  > \begin{aligned}
  > D\left(\sum _{i=1}^{n}X_{i}\right)=\sum _{i=1}^{n}D(X_{i})+2\sum _{i,j\,:\,i<j}Cov (X_{i},X_{j})
  > \end{aligned}
  > $$
  > *少数分布的随机变量 $X$ 没有均值也没有方差，如柯西分布概率密度函数* 
  > $$
  > \begin{aligned}
  > f(x;x_0,\gamma)=&
  > \frac{1}{\pi\gamma \left[1 + \left(\frac{x-x_0}{\gamma}\right)^2\right]}\\
  > =&{1 \over \pi }\left[{\gamma \over (x-x_0)^{2}+\gamma ^{2}}\right]\\
  > \\
  > &\text{when}\;x_0=0\;\text{and}\;\gamma=1\;\text{是标准柯西分布}\\
  > \\
  > f(x;0,\gamma)=&
  > \frac{1}{\pi\left(1 + x^2\right)}
  > \end{aligned}
  > $$
  > *$X_0$ 定义分布峰值位置，$\gamma>0$ 定义分布半峰位置*

- **总体均值与样本均值以及总体方差与样本方差**

  > *总体均值与总体方差的估计量是样本均值与样本方差* 

  > *总体均值是客观存在的具有某一特性的一类事物的全体 $N$ 的加权平均，其期望 $\mu$ 是真值*
  >
  > *样本均值是从总体中抽出 $n$ 份个体的加权平均 $X_n$ 期望将等于 $\mu$ 无系统误差是无偏估计量*

  > *全体随机变量为 $X_1,X_2,\cdots,X_N$ 则总体方差为 $D(X_N)=\sigma^2 = \frac{1}{N}\sum^N_{k=1}(X_k-\mu)^2$ 是真值*
  >
  > *全体随机变量的抽样为 $X_1,X_2,\cdots,X_n$ 的样本方差为 $D(X_n)=S^2 = \frac{1}{n}\sum^n_{k=1}(X_k-\overline{X}_n)^2=\frac{(n-1)\sigma^2}{n}$ 是有偏估计量，因为总有 $\sum^n_{k=1}(X_k-\overline{X}_n)^2\leq\sum^n_{k=1}(X_k-\mu)^2$ 低估啦方差， $D(X_n)=S^2 = \frac{1}{n-1}\sum^n_{k=1}(X_k-\overline{X}_n)^2=\sigma^2$ 则是无偏估计量*
  > $$
  > \begin{aligned}
  > S^2=&\frac{1}{n-1}\sum^n_{k=1}(X_k-\overline{X}_n)^2\\
  > =&\frac{1}{n-1}\sum^n_{k=1}\left[(X_k-\mu)-(\overline{X}_n-\mu)\right]^2\\
  > =&\frac{1}{n-1}\left[\sum^n_{k=1}(X_k-\mu)^2-2\sum^n_{k=1}(X_k-\mu)(\overline{X}_n-\mu)+\sum^n_{k=1}(\overline{X}_n-\mu)^2\right]\\
  > =&\frac{1}{n-1}\left[\sum^n_{k=1}(X_k-\mu)^2-2(\overline{X}_n-\mu)\cdot\sum^n_{k=1}(X_k-\mu)+\sum^n_{k=1}(\overline{X}_n-\mu)^2\right]\\
  > =&\frac{1}{n-1}\left[\sum^n_{k=1}(X_k-\mu)^2-2(\overline{X}_n-\mu)\cdot\sum^n_{k=1}(X_k-\mu)+n\cdot(\overline{X}_n-\mu)^2\right]\\
  > =&\frac{1}{n-1}\left[\sum^n_{k=1}(X_k-\mu)^2-2(\overline{X}_n-\mu)\cdot n\cdot(\overline{X}_n-\mu)+n\cdot(\overline{X}_n-\mu)^2\right]\\
  > =&\frac{1}{n-1}\left[\sum^n_{k=1}(X_k-\mu)^2-n\cdot(\overline{X}_n-\mu)^2\right]\\
  > =&\frac{1}{n-1}\left[\sum^n_{k=1}\sigma_{X_k}^2-n\sigma_{\overline{X}_n}^2\right]\\
  > =&\frac{1}{n-1}\left[n\sigma^2-n(\frac{\sigma^2}{n})\right]\\
  > =&\sigma^2\\
  > \\
  > &\begin{aligned}
  > &\text{其中}\;\sigma_{X_k}^2\;\text{抽样数}\;n\;\text{足够大可以认为等价}\;\sigma^2\\
  > &\text{其中}\;\sigma_{\overline{X}_n}^2\;\text{抽样的随机变量独立同分布则}\;\sum _{i,j\,:\,i<j}Cov (X_{i},X_{j})=0\;\text{即可以认为方差等价}\;\sigma^2\\
  > \\
  > &\begin{aligned}
  > \sigma_{\overline{X}_n}^2
  > =&\left[\left(\frac{X_1+X_2+\cdots+X_n}{n}\right)-\mu\right]^2\\
  > =&\frac{\left[(X_1-\mu)+(X_2-\mu)+\cdots+(X_n-\mu)\right]^2}{n^2}\\
  > =&\frac{n\cdot E[(X_k-\mu)^2]}{n^2}\\
  > =&\frac{\sigma^2}{n}
  > &\end{aligned}
  > &\end{aligned}
  > \end{aligned}
  > $$
  > 

- **强大数定律**

  > *强大数定律描述样本均值 <font face="楷体" color=red> 几乎确定收敛 </font> 于总体均值* 
  > $$
  > \begin{aligned}
  > &\forall\epsilon>0,\;P\{\lim_{n\rightarrow\infty}{\mid\overline{X}_n-E(X_n)\mid<\epsilon}\}=1\\
  > &\forall\epsilon>0,\;\exists N\in {\Bbb{N}}^+,\;\text{When}\;n>N,\;P\{\mid\overline{X}_n-E(X_n)\mid<\epsilon\}=1\\
  > &\overline{X}_n\stackrel{\mathrm{a.s.}}{\longrightarrow}E(X_n)
  > \end{aligned}
  > $$
  > *也就是说最终样本均值收敛于总体均值的概率为 $1$，即样本均值函数的变量样本数超过界限后样本均值函数只存在有限跳跃间断点偏离总体均值超过 $\epsilon$* 

- **弱大数定律**

  > *弱大数定律描述样本均值 <font face="楷体" color=red> 依概率收敛 </font> 于总体均值* 
  > $$
  > \begin{aligned}
  > &\forall\epsilon>0,\;\lim_{n\rightarrow\infty}P\{\mid\overline{X}_n-E(X_n)\mid<\epsilon\}=1\\
  > &\forall\epsilon>0,\;\exists \delta>0,\;\exists N\in {\Bbb{N}}^+,\;\text{When}\;n>N,\;\mid P\{\mid\overline{X}_n-E(X_n)\mid<\epsilon\}-1\mid <\delta\\
  > &\overline{X}_n\stackrel{\mathrm{P}}{\longrightarrow}E(X_n)
  > \end{aligned}
  > $$
  > *也就是说最终样本均值收敛于总体均值的概率接近为 $1$，即样本均值函数的变量样本数超过界限后样本均值函数偏离总体均值超过 $\epsilon$ 的概率小于 $\delta$，意味着可以有无限的偏离点*



**大数定律衍生了诸多定理，在时间脉络上首先是基于弱大数定律的「伯努利大数定理」、「切比雪夫大数定理」和「辛钦大数定理」其次是基于强大数定律的「波莱尔强大数定理」与「柯尔莫哥洛夫强大数定理」**

- **伯努利大数定理**

  > *设 $X_1,X_2,\cdots,X_n$ 是一系列独立同分布的事件，存在 $P(X_k=1)=p$ 与 $P(X_k=0)=1-p$ 其中 $k=1,2,\cdots,n$ 以及概率 $p\in[0,1]$，若前 $n$ 项和 $S_n=\sum^n_{k=1}X_k$，则任意的正数 $\epsilon$ 满足公式 $(1)$*
  > $$
  > \tag{1}
  > \lim_{n\rightarrow\infty}P\left\{\mid\frac{S_n}{n}-p\mid<\epsilon\right\}=1
  > $$
  > *事件的频率 $\frac{S_n}{n}$ <font face="楷体" color=red> 依概率收敛 </font> 于概率 $p$*
  >
  > *约束条件为事件是独立的伯努利分布，均值存在且相同为 $p$ 和方差存在且相同为 $p(1-p)$*
  >
  > *切比雪夫不等式表明，任意 $\epsilon>0$ 有随机变量 $X$ 使得 $P\left\{\mid X- E(X)\mid\geq\epsilon\right\}\leq\frac{D(X)}{\epsilon^2}$* 
  > $$
  > \begin{aligned}
  > P\left\{\mid X- E(X)\mid\geq\epsilon\right\}
  > =&\int_{\mid x-\mu\mid\geq\epsilon}f(x)\,dx\\
  > \leq&\int_{\mid x-\mu\mid\geq\epsilon}\left(\frac{\mid x-\mu\mid}{\epsilon}\right)^2\cdot f(x)\,dx\\
  > \leq&\int_{-\infty}^{+\infty}\left(\frac{\mid x-\mu\mid}{\epsilon}\right)^2\cdot f(x)\,dx\\
  > =&\frac{D(X)}{\epsilon^2}
  > \end{aligned}
  > $$
  > *证明式 $(1)$ 等价形式 $\lim{n\rightarrow\infty},\;P\{\mid \frac{S_n}{n}- p\mid\geq\epsilon\}=0$*
  > $$
  > \begin{aligned}
  > &\because\quad\lim_{n\rightarrow\infty}P\{\mid \frac{S_n}{n}-p\mid\geq\epsilon\}
  > \leq \lim_{n\rightarrow\infty}\frac{p(1-p)}{n\epsilon^2}=0\\
  > &\because\quad\ P\{\mid \frac{S_n}{n}-p\mid\geq\epsilon\}\geq0\\
  > &\therefore\quad\ 0\leq\lim_{n\rightarrow\infty}P\{\mid \frac{S_n}{n}-p\mid\geq\epsilon\}\leq0\\
  > &\therefore\quad\ \lim_{n\rightarrow\infty}P\{\mid \frac{S_n}{n}-p\mid\geq\epsilon\}=0
  > \end{aligned}
  > $$

- **切比雪夫大数定理**

  > *设 $X_1,X_2,\cdots,X_n$ 是一系列相互独立的随机变量，存在期望 $E(X_k)=\mu_k<M_1$ 与方差 $D(X_k)=\sigma_k^2=M_2$ 其中 $M_1$ 与 $M_2$ 是常数，则任意的正数 $\epsilon$ 满足公式 $(2)$*
  > $$
  > \tag{2}
  > \lim_{n\rightarrow\infty}P\left\{\mid\frac{1}{n}\sum^n_{k=1}X_k-\frac{1}{n}\sum^n_{k=1}\mu_k\mid<\epsilon\right\}=1
  > $$
  > *随机变量的均值 $\overline{X}_n$ <font face="楷体" color=red> 依概率收敛 </font> 于 $E(\mu_k)$*
  >
  > *约束条件为随机变量相互独立，随机变量的均值存在不一定相同，随机变量的方差存在且相同* 

- **辛钦大数定理**

  > *设 $X_1,X_2,\cdots,X_n$ 是一系列独立同分布的随机变量，存在期望 $E(X_k)=\mu$，则任意的正数 $\epsilon$ 满足公式 $(3)$*
  > $$
  > \tag{3}
  > \lim_{n\rightarrow\infty}P\left\{\mid\frac{1}{n}\sum^n_{k=1}X_k-\mu\mid<\epsilon\right\}=1
  > $$
  > *随机变量的均值 $\overline{X}_n$ <font face="楷体" color=red> 依概率收敛 </font> 于 $\mu$*
  >
  > *约束条件为随机变量相互独立，随机变量的均值存且相同，随机变量的方差不要求存在* 

- **波莱尔强大数定理**

  > *设 $X_1,X_2,\cdots,X_n$ 是一系列独立同分布的随机变量，存在 $P(X_k=1)=p$ 与 $P(X_k=0)=1-p$ 其中 $k=1,2,\cdots,n$ 以及概率 $p\in(0,1)$，若前 $n$ 项和 $S_n=\sum^n_{k=1}X_k$，则任意的正数 $\epsilon$ 满足公式 $(4)$*
  > $$
  > \tag{4}
  > P\left\{\lim_{n\rightarrow\infty}\mid\frac{1}{n}\sum^n_{k=1}X_k-\mu\mid<\epsilon\right\}=1
  > $$
  > *随机变量的均值 $\frac{S_n}{n}$ <font face="楷体" color=red> 几乎必然收敛 </font> 于 $p$*
  >
  > *约束条件与伯努利大数定理相同* 

- **柯尔莫哥洛夫强大数定理**

  > 1. *设 $X_1,X_2,\cdots,X_n$ 是一系列独立同分布的随机变量，存在期望 $E(X_n)=\mu$，则任意的正数 $\epsilon$ 满足公式 $(5)$*
  >
  > $$
  > \tag{5}
  > P\left\{\lim_{n\rightarrow\infty}\mid\frac{1}{n}\sum^n_{k=1}X_k-\mu\mid<\epsilon\right\}=1
  > $$
  >
  > 2. *设 $X_1,X_2,\cdots,X_n$ 是一系列相互独立的随机变量，存在期望 $E(X_k)=\mu_k$ 与方差 $D(X_k)=\sigma_k^2$ 其中 $\sigma_k^2$ 有限，则任意的正数 $\epsilon$ 满足公式 $(6)$*
  >
  > $$
  > \tag{6}
  > P\left\{\lim_{n\rightarrow\infty}\mid\frac{1}{n}\sum^n_{k=1}X_k-\frac{1}{n}\sum^n_{k=1}\mu_k\mid<\epsilon\right\}=1
  > $$
  >
  > *随机变量的均值 $\overline{X}_n$ <font face="楷体" color=red> 几乎必然收敛 </font> 于 $\mu$*
  >
  > 1. *约束条件为随机变量相互独立，随机变量的均值存且相同，随机变量的方差不要求存在*
  > 2. *约束条件为随机变量相互独立，随机变量的均值与方差存在且不一定相同*



### **中心极限定理**

**中心极限定理表明只要样本够多不论样本属于何种分布，样本均值会服从以总体均值为 $\mu$，总体方差为 $\sigma^2$ 的正态分布。假设全部随机变量是 $X_1,X_2,\cdots,X_n,X_{n+1},\cdots,X_{N}$，进行 $N-n$ 组抽样，每组抽样数为 $n$，最终得到 $\{\;\{X_1,X_2,\cdots,X_n\},\{X_2,X_3,\cdots,X_{n+1}\},\cdots,\{X_{(N-n)+1},X_{(N-n)+2},\cdots,X_N\}\;\}$ 分别计算每组的样本均值都将满足正态分布 $f(x)={{1}\over{\sigma {\sqrt {2\pi }}}}e^{-{\frac {1}{2}}\left({\frac {x -\mu }{\sigma }}\right)^{2}}$ 其中 $\lim{N-n\to \infty },\bar{x}=\frac{\sum^{N-n}x}{N-n}=\mu,x\in\{\overline{X}_1,\overline{X}_2,\cdots,\overline{X}_{N-n}\}$**

- **概率分布的特征函数**

  > *统计学通过矩系统刻画随机变量的概率分布，常见的矩有一阶矩 $M_1$ 即期望 $\mu=E(\color{red}{X}\color{gray}{)}$、二阶矩 $M_2$ 即方差 $\sigma^2=E(\color{red}{(X-\mu)^2}\color{gray}{)}$、三阶矩 $M_3$ 即偏态 $\tilde{\mu}_3=E((\frac{\color{red}{X-\mu}}{\sigma})\color{red}{^{3}}\color{gray}{)}$ 度量概率分布的不对称性和四阶矩 $M_4$ 即峰态 $\kappa=E((\frac{\color{red}{X-\mu}}{\sigma})\color{red}{^4}\color{gray}{)}$ 度量概率分布的陡峭程度等。随机变量的特征函数包含了它的全部的矩从另一个角度定义了概率分布*
  >
  > *连续的随机变量 $X$ 的概率密度函数为 $f(x)$，特征函数为 $\varphi_X(t)=E(e^{itX})=\int_{-\infty}^{+\infty}e^{itx}f(x)\,dx\;,t\in\Bbb{R}$ 是 $t$ 的复变函数，Herbert Wilf 比喻它是一个上面挂一串数字展示的晒衣绳，从泰勒级数角度看 $e^{itX}$ 等价 $1+\frac{itX}{1}-\frac{t^2X^2}{2!}+\cdots+\frac{(it)^nX^n}{n!}$ 也即 $E(e^{itX})=1+\frac{itE(X)}{1}-\frac{t^2E(X^2)}{2!}+\cdots+\frac{(it)^nE(X^n)}{n!}$ 其中包含各阶矩，对 $t$ 求导得 $k$ 阶矩 $\varphi_X^{(k)}(0)=i^kE(X^k)$；从傅立叶变换的角度看 $F_X(t)=\int_{-\infty}^{+\infty}e^{-itx}f(x)\,dx$ 概率密度函数的特征函数与其傅立叶变换共轭 $\varphi_X(t)=\overline{F_X(t)}$，根据欧拉公式 $e^{ix}=cos(x)+isin(x)$ 可知特征函数实质上就是等价于变换到了傅立叶坐标系*
  >
  > *特征函数虽然不如概率密度函数直观反应各种可能性，但是无法得知概率密度函数时可以先计算出各阶矩然后估计特证函数并通过反变换求解概率密度函数从而描述随机变量的概率分布*
  >
  > *对于独立随机变量 $Y_1=aX+b$ 与 $Y_2=X_1+X_2$ 的特征函数具有公式 $(7)$ 与 $(8)$ 的性质*
  > $$
  > \tag{7}
  > \begin{aligned}
  > \varphi_{Y_1}(t)=&\varphi_{aX+b}(t)\\
  > =&\int_{-\infty}^{+\infty}e^{it(ax+b)}\cdot f(x)\,dx\\
  > =&e^{ibt}\cdot\int_{-\infty}^{+\infty}e^{i(at)x}\cdot f(x)\,d(x)\\
  > =&e^{ibt}\cdot \varphi_X(at)
  > \end{aligned}
  > $$
  >
  > $$
  > \tag{8}
  > \begin{aligned}
  > \varphi_{Y_2}(t)=&\varphi_{X_1+X_2}(t)\\
  > =&\iint_{-\infty}^{+\infty}e^{it(x_1+x_2)}\cdot f_1(x_1)\cdot f_2(x_2)\,dx_1dx_2\\
  > =&\int_{-\infty}^{+\infty}e^{itx_1}\cdot f(x_1)\,dx_1\cdot\int_{-\infty}^{+\infty}e^{itx_2}\cdot f_2(x_2)\,dx_2\\
  > =&\varphi_{X_1}(t)\cdot \varphi_{X_2}(t)
  > \end{aligned}
  > $$
  >
  > *若随机变量 $X～\mathcal{N}(0,1)$ 其概率密度函数为<font face="楷体" color=red> 正态分布 </font> $f(x)=\frac{1}{\sqrt{2\pi}}e^{{\frac{-x^{2}}{2}}}$ 则有特征函数*
  > $$
  > \begin{aligned}
  > \varphi_X(t)&=\int_{-\infty}^{+\infty}e^{itx}\cdot\frac{1}{\sqrt{2\pi}}e^{{\frac{-x^{2}}{2}}}\,dx\\
  > &=e^{\frac{-t^2}{2}}\cdot\int_{-\infty}^{+\infty}\frac{1}{\sqrt{2\pi}}e^{{\frac{-(x-it)^{2}}{2}}}\,d(x-it)\\
  > &=e^{\frac{-t^2}{2}}
  > \end{aligned}
  > $$

- **林德贝格-勒维中心极限定理**

  > *设 $X_1,X_2,\cdots,X_n$ 是一系列独立同分布的随机变量，前 $n$ 项和 $S_n=\sum^n_{k=1}X_k$ 均值为 $\overline{X}_n=\frac{1}{n}S_n$ 期望为 $E(X_n)=\mu$ 与方差 $D(X_n)=\sigma^2<\infty$，当 ${\textstyle n}$ 趋近无穷大，有公式 $(9)$*
  > $$
  > \tag{9}
  > \begin{aligned}
  > &\begin{aligned}
  > \lim _{n\to \infty } P \left\{{\sqrt {n}}({\overline {X}}_{n}-\mu )\leq z\right\} &=\lim _{n\to \infty } P \left\{{\frac {{\sqrt {n}}({\overline {X}}_{n}-\mu )}{\sigma }}\leq {\frac {z}{\sigma }}\right\}
  > \\&=\Phi(\frac{z}{\sigma})
  > ={\frac {1}{\sqrt {2\pi }}}\int_{-\infty}^{z\over\sigma}e^{-t^{2}/2}\,dt\\
  > \end{aligned}
  > \\&{\sqrt {n}}({\overline {X}}_{n}-\mu )\stackrel{\mathrm{D}}{\longrightarrow}{\mathcal {N}}(0,\sigma ^{2})
  > \end{aligned}
  > $$
  > *随机变量 ${\textstyle {\sqrt {n}}({\overline{X}}_{n}-\mu )}$ <font face="楷体" color=red> 依收分布收敛 </font> 于正态分布 ${\textstyle {\mathcal {N}}(0,\sigma ^{2})}$*
  >
  > *均匀收敛且 ${\displaystyle \lim _{n\to \infty }\;\sup _{z\in \mathbb {R} }\;\left|P \left[{\sqrt {n}}({ \overline{X}}_{n}-\mu )\leq z\right]-\Phi \left({\frac {z}{\sigma }}\right)\right|=0}$* 
  >
  > *证明 $\lim{n\rightarrow\infty},\;\frac{\sqrt{n}({\overline{X}}_{n}-\mu)}{\sigma}\stackrel{\mathrm{D}}{\longrightarrow}{\mathcal{N}}(0,1)$*
  > $$
  > \begin{aligned}
  > &\because\;
  > \text{式}(7),(8)\\
  > &\therefore\;
  > \varphi_{S_n}(t)=\left[\varphi_{x}(t)\right]^n,\;\varphi_{\overline{X}_n}(t)=\varphi_{S_n}(\frac{t}{n})=\left[\varphi_{x}(\frac{t}{n})\right]^n\\
  > &\because\;
  > Y=\frac{\sqrt{n}({\overline{X}}_{n}-\mu)}{\sigma}=\frac{\sqrt{n}}{\sigma}{\overline{X}}_{n}-\frac{\sqrt{n}}{\sigma}{\mu}\\
  > &\therefore\;
  > \varphi_{Y}(t)=e^{i(-\frac{\sqrt{n}}{\sigma}\mu)t}\cdot \varphi_{\overline{X}_n}(\frac{\sqrt{n}}{\sigma}t)=e^{i(-\frac{\sqrt{n}}{\sigma}\mu)t}\cdot \left[\varphi_{X}(\frac{t}{\sigma\sqrt{n}})\right]^n
  > \\
  > &\therefore
  > \\
  > &\begin{aligned}
  > \quad\;\; ln\left[\varphi_{Y}(t)\right]
  > =&\;ln\left\{e^{i(-\frac{\sqrt{n}}{\sigma}\mu)t}\cdot \left[\varphi_{X}(\frac{t}{\sigma\sqrt{n}})\right]^n\right\}\\
  > =&\;-i\frac{\sqrt{n}}{\sigma}\mu t+n\cdot ln\left[\varphi_{X}(\frac{t}{\sigma\sqrt{n}})\right]\\
  > =&\;n\left\{-i\mu\frac{t}{\sigma\sqrt{n}}+ln\left[\varphi_{X}(\frac{t}{\sigma\sqrt{n}})\right]\right\}
  > \\
  > \end{aligned}
  > \\
  > &\because\;
  > p=\frac{t}{\sigma\sqrt{n}},\;\lim_{n\rightarrow\infty}p=0,\;\lim_{n\rightarrow\infty}\varphi_{X}(p)=\varphi_{X}(0)
  > \\
  > &\because
  > \\
  > &\begin{aligned}
  > \quad\;\;
  > \varphi_{X}(0)=&\int_{-\infty}^{+\infty}f(x)\,dx=1\\
  > \varphi^\prime_{X}(0)=&\int_{-\infty}^{+\infty}ixf(x)\,dx=i\mu\\
  > \varphi^{\prime\prime}_{X}(0)=&\int_{-\infty}^{+\infty}-x^2f(x)\,dx=-\mu^2-\sigma^2\\
  > \end{aligned}
  > \\
  > &\therefore
  > \\
  > &\begin{aligned}
  > \quad\;\;
  > \lim_{n\rightarrow\infty}ln[\varphi_{Y}(t)]
  > =&\lim_{n\rightarrow\infty}n\left\{-i\mu\frac{t}{\sigma\sqrt{n}}+ln\left[\varphi_{X}(\frac{t}{\sigma\sqrt{n}})\right]\right\}\quad(\text{e.g.}\;\;0\cdot\infty)\\
  > =&\frac{t^2}{\sigma^2}\cdot\lim_{p\rightarrow0}\frac{-i\mu p+ln\left[\varphi_{X}(p)\right]}{p^2}\\
  > =&\frac{t^2}{\sigma^2}\cdot\lim_{p\rightarrow0}\frac{-i\mu+\left[\varphi_{X}(p)\right]^{-1}\cdot\varphi^{\prime}_{X}(p)}{2p}\\
  > =&\frac{t^2}{\sigma^2}\cdot\lim_{p\rightarrow0}\frac{\varphi^{\prime\prime}_{X}(p)\cdot\varphi_{X}(p)-\varphi^{\prime}_{X}(p)\cdot\varphi^{\prime}_{X}(p)}{2[\varphi_{X}(p)]^2}\\
  > =&\frac{t^2}{\sigma^2}\cdot\frac{\varphi^{\prime\prime}_{X}(0)\cdot\varphi_{X}(0)-[\varphi^{\prime}_{X}(0)]^2}{2[\varphi_{X}(0)]^2}\\
  > =&\frac{t^2}{\sigma^2}\cdot\frac{(-\mu^2-\sigma^2)\cdot1-(i\mu)^2}{2\cdot1}\\
  > =&-\frac{t^2}{2}
  > \end{aligned}
  > \end{aligned}
  > $$
  > *故 $\lim{n\rightarrow\infty},\;\varphi_Y(t)=e^{-\frac{t^2}{2}}$ 得证*

- **李雅普诺夫中心极限定理**

  > 设 $X_{1},\cdots ,X_{n}$ 是一系列独立随机变量，每个变量都有有限的期望 $\mu_k$ 和方差 $\sigma _{k}^{2}$ 定义 $S_n^2=\sum^{n}_{k=1}\sigma_k^2$，有公式 $(10)$
  > $$
  > \tag{10}
  > \begin{aligned}
  > &\exists\delta>0,\;\lim_{n\rightarrow\infty}\frac{1}{S_n^{2+\delta}}\cdot\sum_{k=1}^{n}E\left[\mid X_k-\mu_k\mid^{2+\delta}\right]=0\\
  > &{\frac{1}{S_n}}\sum_{k=1}^{n}({X}_{k}-\mu_k)\stackrel{\mathrm{D}}{\longrightarrow}{\mathcal {N}}(0,1)
  > \end{aligned}
  > $$
  > *随机变量的线性和 ${\frac{1}{S_n}}\sum_{k=1}^{n}({X}_{k}-\mu_k)$ <font face="楷体" color=red> 依收分布收敛 </font> 于正态分布 ${\textstyle {\mathcal {N}}(0,\sigma ^{2})}$*
  >
  > *通常使用检验条件 $\delta=1$*



### **连续分布**

#### **正态分布**

**正态分布 *(Normal Distribution)* 也称常态分布或正常分布，一般记作 $X～\mathcal{N}(\mu,\sigma^2)$，其概率密度函数为 $f(x)={\frac {1}{\sigma {\sqrt {2\pi }}}}e^{-{\frac {1}{2}}\left({\frac {x -\mu }{\sigma }}\right)^{2}}$，标准正态分布即高斯分布为 $\mu=1,\;\sigma^2=0,\;f(x)=\frac{1}{\sqrt{2\pi}}e^{{\frac{-x^{2}}{2}}}$ 其累积分布函数为 $\Phi (x)={\frac {1}{\sqrt {2\pi }}}\int _{-\infty }^{x}e^{-t^{2}/2}\,dt$ 泰勒近似为 ${\frac {1}{2}}+{\frac {1}{\sqrt {2\pi }}}\sum _{k=0}^{n}{ \frac {\left(-1\right)^{k}x^{\left(2k+1\right)}}{2^{k}k!\left(2k+1\right)}}$**

- **高斯推导**

  > *设 $x_{1},\cdots ,x_{n}$ 是真值 $x$ 的一系列独立观测值 $\bar{x}=\frac{1}{n}\sum^{n}_{k}x_k$，误差 $\theta$ 中 $\theta_k=x_k-x,\;k=1,2,\cdots,n$  其概率密度函数为 $f(\theta)$，似然函数为 $L(\theta)=\prod_{k=1}^{n}f(\theta_k)$，假设 $\lim{n\rightarrow\infty},x=\bar{x},\theta_k=x_k-\bar{x}$ 进行极大似然估计*
  > $$
  > \begin{aligned}
  > \because
  > \\&\begin{aligned}
  > L(\theta)=\prod_{k=1}^{n}f(\theta_k)
  > =&\prod_{k=1}^{n}f(x_k-\bar{x})\\
  > \frac{d}{dx}ln\left[\prod_{k=1}^{n}f(\theta_k)\right]
  > =&\frac{d}{dx}\left\{\sum_{k=1}^{n}ln[f(x_k-\bar{x})]\right\}\\
  > =&-\sum_{k=1}^{n}\frac{f^\prime(x_k-\bar{x})}{f(x_k-\bar{x})}
  > \end{aligned}\\
  > \therefore
  > \\&\sum_{k=1}^{n}\frac{f^\prime(x_k-\bar{x})}{f(x_k-\bar{x})}
  > =0\\
  > \because
  > \\&\lim{n\rightarrow\infty}\Rightarrow\theta_k=x_k-\bar{x}=x_k-x:=t\Rightarrow\frac{f^\prime(t)}{f(t)}=g(t)\\
  > \therefore
  > \\&G(t)=\sum_{k=1}^{n}g(x_k-x)=0
  > \\&G^\prime(t)=\sum_{k=1}^{n}\frac{\partial[g(x_k-x)]}{\partial x_k}=0\\
  > \therefore
  > \\&\begin{aligned}
  > &g^\prime(x_1-x)(1-\frac{1}{n})+g^\prime(x_2-x)(-\frac{1}{n})+\cdots+g^\prime(x_n-x)(-\frac{1}{n})=0\\
  > &g^\prime(x_1-x)(-\frac{1}{n})+g^\prime(x_2-x)(1-\frac{1}{n})+\cdots+g^\prime(x_n-x)(-\frac{1}{n})=0\\
  > &\vdots\\
  > &g^\prime(x_1-x)(1-\frac{1}{n})+g^\prime(x_2-x)(-\frac{1}{n})+\cdots+g^\prime(x_n-x)(-\frac{1}{n})=0\\
  > \end{aligned}\\
  > \because
  > \\&\begin{bmatrix}   
  > 1-\frac{1}{n} & -\frac{1}{n} & \cdots & -\frac{1}{n} \\   
  > -\frac{1}{n} & 1-\frac{1}{n} & \cdots & -\frac{1}{n} \\  
  > \vdots & \vdots & \ddots & -\frac{1}{n} \\
  > -\frac{1}{n} & -\frac{1}{n} & \cdots & 1-\frac{1}{n} \\
  > \end{bmatrix}\begin{bmatrix}   
  > g^\prime(x_1-x)\\   
  > g^\prime(x_2-x)\\   
  > \vdots\\
  > g^\prime(x_n-x)\\
  > \end{bmatrix}=\begin{bmatrix}   
  > 0\\   
  > 0\\   
  > \vdots\\
  > 0\\
  > \end{bmatrix}\\
  > \therefore
  > \\&g^\prime(x_k-x)=C,\;k=1,2,\cdots,n\\
  > &\sum_{k=1}^{n}g(x_k-x)=\sum_{k=1}^{n}C(x_k-x)+nb=0+nb=0\Rightarrow b=0\\
  > \therefore
  > \\&g(t)=\frac{f^\prime(t)}{f(t)}=Ct\\
  > &f(t)=Ae^{\frac{1}{2}Ct^2}\\
  > \because
  > \\&\Phi(\theta)=\lim_{n\rightarrow\infty}\sum^{n}_{k=1}f(x_k-\bar{x})=\sum^{\infty}_{k=1}f(x_k-x)=\int_{-\infty}^{+\infty}f(\theta)\,d\theta=1\\
  > &C=\lim_{n\rightarrow\infty}\sum_{k=1}^{n}\frac{-n}{(x_k-\bar{x})^2}=-\frac{1}{\sigma^2}\Longrightarrow A=\frac{1}{\sqrt{2\pi}\sigma}\\
  > \therefore
  > \\&f(\theta)={\frac {1}{\sigma {\sqrt {2\pi }}}}e^{-{\frac {1}{2}}\left({\frac {\theta - x }{\sigma }}\right)^{2}}\\
  > &x=1,\;\sigma^2=0,\;f(\theta)=\frac{1}{\sqrt{2\pi}}e^{{\frac{-\theta^{2}}{2}}}\Longrightarrow\Phi(\theta)={\frac {1}{\sqrt {2\pi }}}\int _{-\infty }^{\theta}e^{-y^{2}/2}\,dy
  > \end{aligned}
  > $$
  
-  **特性**

  > *随机变量 $X_1～\mathcal{N}(\mu_1,\sigma_1^2)$ 和 $X_2～\mathcal{N}(\mu_2,\sigma_2^2)$ 相互独立，那么具有再生性 $X_1+X_2～\mathcal{N}(\mu_1+\mu_2,\sigma_1^2+\sigma_2^2)$*



#### **均匀分布**

**均匀分布即矩形分布，描述界限之间的任意随机变量 $X$ 的概率，界限的最小值和最大值为 $a$ 与 $b$ ，一般记作 $X～U(a,b)$，其概率密度函数为 $f(x)=\frac{1}{b-a}\;if\;x\in(a,b)\,\pmb{or}\,[a,b]\;\pmb{and}\;f(x)=0\;if\;otherwise$ 均值 $\mu=\frac{b+a}{2}$ 和方差 $\sigma^2=\frac{(b-a)^2}{12}$**  

- **特性**

  > *概率密度函数也可写为*
  > $$
  > f(x)={\begin{cases}{\frac {1}{2\sigma {\sqrt {3}}}}&{\mbox{for }}-\sigma {\sqrt {3}}\leq x-\mu \leq \sigma {\sqrt {3}}\\0&{\text{otherwise}}\end{cases}}
  > $$
  > *累积分布函数为* 
  > $$
  > F(x)={\begin{cases}0&{\text{for }}x<a\\[8pt]{\frac {x-a}{b-a}}&{\text{for }}a\leq x\leq b\\[8pt]1&{\text{for }}x>b\end{cases}}
  > $$
  > *累积分布函数也可写为*
  > $$
  > F(x)={\begin{cases}0&{\text{for }}x-\mu <-\sigma {\sqrt {3}}\\{\frac {1}{2}}\left({ \frac {x-\mu }{\sigma {\sqrt {3}}}}+1\right)&{\text{for }}-\sigma {\sqrt {3}}\leq x-\mu < \sigma {\sqrt {3}}\\1&{\text{for }}x-\mu \geq \sigma {\sqrt {3}}\end{cases}}
  > $$



#### **指数分布**

**指数分布描述无记忆性的随机变量，一般记作 $X～\mathrm{Exp}(\lambda)$，其概率密度函数为 $f(x;\lambda )=\lambda e^{-\lambda x}\;if\;x\geq 0\;\pmb{and}\;0\;if\;x<0$ 其中 $\lambda> 0 $ 是分布的速率参数，均值 $E[X]={\frac {1}{\lambda }}$ 方差 $D[X]={\frac {1}{\lambda^2 }}$**

- **特性**

  > *累积分布函数为*
  > $$
  > F(x;\lambda) = \begin{cases} 1-e^{-\lambda x} & x \ge 0 \\ 0 & x < 0\end{cases}
  > $$
  > *分位数函数为*
  > $$
  > F^{-1}(p;\lambda )={\frac {-\ln(1-p)}{\lambda }},\qquad 0\leq p<1
  > $$
  > *假设随机变量是时间，其无记忆性指在以初始时间段 $s$ 内未能观察到事件为条件时剩余等待时间的分布与原始的无条件分布相同，这初始时间段 $s$ 也即沉默成本*
  > $$
  > P\left(X>s+t\mid X>s\right)=P(X>t),\qquad \forall s,t\geq 0
  > $$
  > *泊松过程中事件间间隔时间的概率分布服从指数分布*



### **离散分布**

#### **伯努利分布**

**伯努利分布即两点分布，离散随机变量 $X\in\{0,1\}$，随机变量 $X=1$ 的概率 $p\in[0,1]$ 随机变量 $X=0$ 的概率 $q=1-p$，均值 $E(X)=p$ 方差 $D(X)=pq=p-p^2$**

- **核心**

  > $$
  > \begin{aligned}
  > P(X;p)=&p^X(1-p)^{(1-X)}\\
  > =&p^Xq^{(1-X)}\\
  > \tilde{\mu}_3=&E\left\{\left[{\frac {X-E(X)}{\sqrt {D (X)}}}\right]^{3}\right\}\\=&p\cdot \left({\frac {q}{\sqrt {pq}}}\right)^{3}+ q\cdot \left(-{\frac {p}{\sqrt {pq}}}\right)^{3}\\=&{\frac {1}{{\sqrt {pq}}^{3} }}\left(pq^{3}-qp^{3}\right)\\=&{\frac {pq}{{\sqrt {pq}}^{3}}}(qp)= {\frac {qp}{\sqrt {pq}}}
  > \end{aligned}
  > $$



#### **二项分布**

**二项分布的本质是伯努利分布**

- **核心**

  > *离散随机变量 $X$ 独立发生 $n$ 次的伯努利事件构成二项分布，一般记作 $X～\mathcal{B}(n,p)$，描述 $n$ 次中恰好有 $k$ 次 $X=1$ 的概率，均值 $E(X)=np$ 方差 $D(X)=npq=n(p-p^2)$*
  > $$
  > \begin{aligned}
  > f(k,n,p)&={\binom {n}{k}}p^{k}(1-p) ^{n-k}\\
  > &=\binom {n}{k}\prod^{n} p^Xq^{(1-X)}\\
  > &\binom {n}{k}=\frac {n!}{k!(n-k)!}
  > \end{aligned}
  > $$
  > *当 $n=1$ 时二项分布退化为伯努利分布* 



#### **泊松分布**

**泊松分布的本质是二项分布**

- **核心**

  > *离散随机变量 $X$ 具有泊松分布，是二项分布的次数 $n$ 趋近无穷的情况，参数为 $\lambda >0\;\;\text{e.g.}\;\lambda=np$ 其中 $p$ 是伯努利事件发生的概率，概率质量函数* 
  > $$
  > f(k; \lambda)=\frac{\lambda^ke^{-\lambda}}{k!}
  > $$
  > *考虑一个具体问题，一天内公交车站点经停 $k$ 俩公交车的概率 $P(k)$，假设一天包含 $n$ 份单位时间，单位时间内公交车经过公交车站点停下是独立随机的且概率是 $p$，因此 $P(k)$ 可以用 ${\binom {n}{k}}p^{k}(1-p) ^{n-k}$ 描述，假设期望是 $\lambda=np$ 则可知 $p=\frac{\lambda}{n}$，单位时间需要足够精细即 $n\rightarrow\infty$ 使得单位时间内最多仅一辆公交车经停，则有* 
  > $$
  > \begin{aligned}
  > P(k)
  > =&\lim_{n\rightarrow\infty}\left\{{\binom {n}{k}}\left(\frac{\lambda}{n}\right)^{k}\left(1-\frac{\lambda}{n}\right)^{n-k}\right\}\\
  > =&\lim_{n\rightarrow\infty}\left\{\left[\frac{n(n-1)(n-2)\cdots(n-k+1)}{k!}\right]\left(\frac{\lambda}{n}\right)^{k}\left(1-\frac{\lambda}{n}\right)^{n-k}\right\}\\
  > =&\lim_{n\rightarrow\infty}\left\{\frac{\lambda^{k}}{k!}\cdot\left(1-\frac{\lambda}{n}\right)^{n}\cdot\left[\frac{n(n-1)(n-2)\cdots(n-k+1)}{n^k}\right]\cdot\left(1-\frac{\lambda}{n}\right)^{-k}\right\}\\
  > =&\lim_{n\rightarrow\infty}\frac{\lambda^{k}}{k!}\cdot\lim_{n\rightarrow\infty}\left(1-\frac{\lambda}{n}\right)^{n}\cdot\lim_{n\rightarrow\infty}\left[\frac{n(n-1)(n-2)\cdots(n-k+1)}{n^k}\right]\cdot\lim_{n\rightarrow\infty}\left(1-\frac{\lambda}{n}\right)^{-k}\\
  > =&\lim_{n\rightarrow\infty}\frac{\lambda^{k}}{k!}\cdot1\cdot1\cdot\lim_{n\rightarrow\infty}\left(1-\frac{\lambda}{n}\right)^{-k}\\
  > =&\frac{\lambda^{k}}{k!}\cdot e^{-\lambda}\\
  > \end{aligned}
  > $$
  > *当二项分布 $n$ 很大 $p$ 很小时难以计算，而 $n$ 很大 $p$ 很小通常可以使用泊松分布近似二项分布快速计算* 



### **假设检验**

### **参数估计**

#### **点估计**

#### **区间估计**

### **非参数估计**

### **随机过程**



## **信息论**

### **信息熵**

### **最大熵原理**

### **散度**



## **优化算法**

**在机器学习中通常会先定义损失函数，一旦我们有了损失函数，就可以使用优化算法来尝试最小化损失。在优化中，损失函数通常被称为优化问题的目标函数**

**优化提供了一种最大限度地减少机器学习损失函数的方法，但实质上两者的目标是不同的，前者主要关注的是最小化目标，后者则关注在给定有限数据量的情况下寻找合适的模型。例如，训练误差和泛化误差通常不同，由于优化算法的目标函数通常是基于训练数据集的损失函数，因此优化的目标是减少训练误差。但是机器学习（或更广义的统计推断）的目标是减少泛化误差，为了实现后者，除了使用优化算法来减少训练误差之外还需要注意过拟合**

- **优化有许多挑战**

  > *例如，局部最小值，对于任何目标函数 $f(x)$，如果在 $x$ 处对应的 $f(x)$ 值小于在 $x$ 附近任何其他点的 $f(x)$ 值，那么 $f(x)$ 可能是局部最小值。如果 $f(x)$ 在 $x$ 处的值是整个域上目标函数的最小值，那么 $f(x)$ 是全局最小值，目标函数通常有许多局部最优解。当优化问题的数值解接近局部最优值时，随着目标函数解的梯度接近或变为零，通过最终迭代获得的数值解可能仅使目标函数局部最优，而不是全局最优*
  >
  > *例如，鞍点，指函数的所有梯度都消失但既不是全局最小值也不是局部最小值的任何位置。对于函数 $f(x)=x^3$。它的一阶和二阶导数在 $x=0$ 时消失，此时优化可能会停止，但不是最小值，对于高维度问题，当函数在零梯度位置处的 $Hessian$ 矩阵的非正定时即为鞍点，这种情况很多，因此，鞍点比局部最小值更有可能*
  >
  > 例如，梯度消失，最小化函数 $f(x)=tanh⁡(x)$，若初值为 $x=4$ 则 $f$ 的梯度接近零，$f^′(4)=1−tanh^2⁡(4)=0.0013$ 优化将会停滞很长一段时间



### **凸性**

**凸性在优化算法的设计中起到至关重要的作用，主要是由于在这种情况下对算法进行分析和测试要容易得多。换言之，如果该算法甚至在凸性条件设定下的效果很差，通常我们很难在其他条件下看到好的结果。此外，即使机器学习中的优化问题通常是非凸的，它们也经常在局部极小值附近表现出一些凸性**



#### **凸集**

**凸集是凸性的基础。简单地说，如果对于任何 $a，b \in \mathcal{X}$，连接 $a$ 和 $b$ 的线段也位于 $\mathcal{X}$ 中，则向量空间中的一个集合 $\mathcal{X}$ 是 凸的。在数学术语上，这意味着对于所有 $\lambda \in [0, 1]$，我们得到**
$$
\lambda  a + (1-\lambda)  b \in \mathcal{X} \text{ 当 } a, b \in \mathcal{X}
$$

**下第一组存在不包含在集合内部的线段，所以该集合是非凸的，而下另外两组则没有这样的问题，所以是凸的**

![第一组是非凸的，另外两组是凸的。](./assets/%E6%88%91%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%BB%E7%BA%BF/pacman.svg)

**假设下第一组 $\mathcal{X}$ 和下第二组 $\mathcal{Y}$ 是凸集，那么 $\mathcal {X} \cap \mathcal{Y}$ 也是凸集的。如下图，现在考虑任意 $a, b \in \mathcal{X} \cap \mathcal{Y}$，因为 $\mathcal{X}$ 和 $\mathcal{Y}$ 是凸集，所以连接 $a$ 和 $b$ 的线段包含在 $\mathcal{X}$ 和 $\mathcal{Y}$ 中。鉴于此，它们也需要包含在 $\mathcal {X} \cap \mathcal{Y}$ 中，从而证明的定理**

![两个凸集的交集是凸的。](./assets/%E6%88%91%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%BB%E7%BA%BF/convex-intersect.svg)

**可以毫不费力地进一步得到，给定凸集 $\mathcal{X}_i$，它们的交集 $\cap_{i} \mathcal{X}_i$ 是凸的。但是反向是不正确的，考虑两个不相交的集合 $\mathcal{X} \cap \mathcal{Y} = \emptyset$，取 $a \in \mathcal{X}$ 和 $b \in \mathcal{Y}$。假设 $\mathcal{X} \cap \mathcal{Y} = \emptyset$，连接 $a$ 和 $b$ 的线段需要包含一部分既不在 $\mathcal{X}$ 也不在 $\mathcal{Y}$ 中。因此线段也不在 $\mathcal{X} \cup \mathcal{Y}$ 中，因此证明了凸集的并集不一定是凸的，即非凸的**

![两个凸集的并集不一定是凸的。](./assets/%E6%88%91%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%BB%E7%BA%BF/nonconvex.svg)

**通常机器学习中的问题是在凸集上定义的。例如，$\mathbb{R}^d$ 即实数的 $d$ 维向量的集合是凸集（毕竟 $\mathbb{R}^d$ 中任意两点之间的线存在 $\mathbb{R}^d$）中。在某些情况下使用有界长度的变量，例如球的半径定义为$\{\mathbf{x} | \mathbf{x} \in \mathbb{R}^d \text{ and } \| \mathbf{x} \| \leq r\}$**



#### **凸函数**

**有了凸集就可以引入凸函数 $f$。给定一个凸集 $\mathcal{X}$，如果对于所有 $x, x' \in \mathcal{X}$ 和所有 $\lambda \in [0, 1]$，函数 $f: \mathcal{X} \to \mathbb{R}$ 是凸的，则可以得到**
$$
\lambda f(x) + (1-\lambda) f(x') \geq f(\lambda x + (1-\lambda) x')
$$
**为了说明这一点，下面定义一些函数，包括凸函数和非凸函数**
$$
\begin{aligned}
f(x)&=0.5\ast x^2 &\text{凸函数}\\
g(x)&=cos(\pi x)&\text{非凸函数}\\
h(x)&=\exp(0.5\ast x)&\text{凸函数}
\end{aligned}
$$
<img src="./assets/%E6%88%91%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%BB%E7%BA%BF/output_convexity_94e148_18_0.svg" alt="../_images/output_convexity_94e148_18_0.svg" style="zoom: 67%;" />

**余弦函数为非凸的，而抛物线函数和指数函数为凸的，且 $\mathcal{X}$ 是凸集的要求是必要的，否则可能无法很好地界定$f(\lambda x + (1-\lambda) x')$ 的结果**



##### **凸函数的局部极小值**

**假设 $x^{\ast} \in \mathcal{X}$ 是一个局部最小值，则存在一个很小的正值 $p$，使得当$x \in \mathcal{X}$ 满足 $0 < |x - x^{\ast}| \leq p$ 时，有 $f(x^{\ast}) < f(x)$**

**现在假设局部极小值 $x^{\ast}$ 不是 $f$ 的全局极小值，存在 $x' \in \mathcal{X}$ 使得 $f(x') < f(x^{\ast})$。则存在 $\lambda \in [0, 1)$，比如 $\lambda = 1 - \frac{p}{|x^{\ast} - x'|}$，使得 $0 < |\lambda x^{\ast} + (1-\lambda) x' - x^{\ast}| \leq p$**

**然而，根据凸性的性质有**
$$
\begin{aligned}
    f(\lambda x^{\ast} + (1-\lambda) x') &\leq \lambda f(x^{\ast}) + (1-\lambda) f(x') \\
    &< \lambda f(x^{\ast}) + (1-\lambda) f(x^{\ast}) \\
    &= f(x^{\ast}) \\
\end{aligned}
$$
**这与 $x^{\ast}$ 是局部最小值相矛盾。因此不存在 $x' \in \mathcal{X}$ 满足 $f(x') < f(x^{\ast})$。综上所述，局部最小值 $x^{\ast}$ 也是全局最小值。例如，对于凸函数 $f(x) = (x-1)^2$，有一个局部最小值 $x=1$，它也是全局最小值**

<img src="./assets/%E6%88%91%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%BB%E7%BA%BF/output_convexity_94e148_30_0.svg" alt="../_images/output_convexity_94e148_30_0.svg" style="zoom:67%;" />

**凸函数的局部极小值同时也是全局极小值这一性质是很方便的。这意味着如果最小化函数就不会卡住。但是这并不意味着不能有多个全局最小值，或者不存在一个全局最小值。例如，函数 $f(x) = \mathrm{max}(|x|-1, 0)$ 在 $[-1,1]$ 区间上都是最小值。相反，函数 $f(x) = \exp(x)$ 在 $\mathbb{R}$ 上没有取得最小值。对于 $x \to -\infty$，它趋近于 $0$，但是没有 $f(x) = 0$ 的 $x$**



##### **凸函数的下水平集**

**通过凸函数的下水平集定义凸集，给定一个定义在凸集 $\mathcal{X}$ 上的凸函数 $f$，其任意一个下水平集**
$$
\mathcal{S}_b := \{x | x \in \mathcal{X} \text{ and } f(x) \leq b\}
$$
**是凸的，对于任何 $x, x' \in \mathcal{S}_b$，需要证明，当 $\lambda \in [0, 1]$时，$\lambda x + (1-\lambda) x' \in \mathcal{S}_b$。因为 $f(x) \leq b$且$f(x') \leq b$，所以**
$$
f(\lambda x + (1-\lambda) x') \leq \lambda f(x) + (1-\lambda) f(x') \leq b
$$

##### **凸性和二阶导数**

**当一个函数的二阶导数 $f: \mathbb{R}^n \rightarrow \mathbb{R}$ 存在时，很容易检查这个函数的凸性。需要做的就是检查 $\nabla^2f \succeq 0$，即对于所有 $\mathbf{x} \in \mathbb{R}^n$，$\mathbf{x}^\top \mathbf{H} \mathbf{x} \geq 0$。例如，函数 $f(\mathbf{x}) = \frac{1}{2} \|\mathbf{x}\|^2$ 是凸的，因为 $\nabla^2 f = \mathbf{1}$，即其导数是单位矩阵**

**更严谨的 $f$ 为凸函数，当且仅当任意二次可微一维函数 $f: \mathbb{R}^n \rightarrow \mathbb{R}$ 是凸的。对于任意二次可微多维函数 $f: \mathbb{R}^{n} \rightarrow \mathbb{R}$，它是凸的当且仅当它的 $Hessian$ 矩阵即 $\nabla^2f\succeq 0$**

**首先，证明一维情况。为了证明凸函数的 $f''(x) \geq 0$，使用**
$$
\frac{1}{2} f(x + \epsilon) + \frac{1}{2} f(x - \epsilon) \geq f\left(\frac{x + \epsilon}{2} + \frac{x - \epsilon}{2}\right) = f(x)
$$
**因为二阶导数是由有限差分的极限给出的，所以遵循**
$$
f''(x) = \lim_{\epsilon \to 0} \frac{f(x+\epsilon) + f(x - \epsilon) - 2f(x)}{\epsilon^2} \geq 0
$$
**为了证明 $f'' \geq 0$ 可以推导 $f$ 是凸的，使用一个事实 $f'' \geq 0$ 意味着 $f'$ 是一个单调的非递减函数。假设$a < x < b$ 是 $\mathbb{R}$ 中的三个点，其中 $x = (1-\lambda)a + \lambda b$ 且 $\lambda \in (0, 1)$ 根据中值定理，存在 $\alpha \in [a, x]$，$\beta \in [x, b]$，使得**
$$
f'(\alpha) = \frac{f(x) - f(a)}{x-a} \text{ 且 } f'(\beta) = \frac{f(b) - f(x)}{b-x}
$$
**通过单调性 $f'(\beta) \geq f'(\alpha)$，因此**
$$
\frac{x-a}{b-a}f(b) + \frac{b-x}{b-a}f(a) \geq f(x)
$$
**由于 $x = (1-\lambda)a + \lambda b$，所以**
$$
\lambda f(b) + (1-\lambda)f(a) \geq f((1-\lambda)a + \lambda b)
$$
**从而证明了凸性**

**其次，需要一个引理证明多维情况 $f: \mathbb{R}^n \rightarrow \mathbb{R}$ 是凸的当且仅当对于所有 $\mathbf{x}, \mathbf{y} \in \mathbb{R}^n$**
$$
g(z) \stackrel{\mathrm{def}}{=} f(z \mathbf{x} + (1-z)  \mathbf{y}) \text{ where } z \in [0,1]
$$
**是凸的**

**为了证明 $f$ 的凸性意味着 $g$ 是凸的，可以证明，对于所有的 $a，b，\lambda \in[0，1]$（这样有 $0 \leq \lambda a + (1-\lambda) b \leq 1$）**
$$
\begin{aligned} &g(\lambda a + (1-\lambda) b)\\
=&f\left(\left(\lambda a + (1-\lambda) b\right)\mathbf{x} + \left(1-\lambda a - (1-\lambda) b\right)\mathbf{y} \right)\\
=&f\left(\lambda \left(a \mathbf{x} + (1-a)  \mathbf{y}\right)  + (1-\lambda) \left(b \mathbf{x} + (1-b)  \mathbf{y}\right) \right)\\
\leq& \lambda f\left(a \mathbf{x} + (1-a)  \mathbf{y}\right)  + (1-\lambda) f\left(b \mathbf{x} + (1-b)  \mathbf{y}\right) \\
=& \lambda g(a) + (1-\lambda) g(b).
\end{aligned}
$$
**为了证明这一点，可以证明对 $[0，1]$ 中所有的 $\lambda$**
$$
\begin{aligned} &f(\lambda \mathbf{x} + (1-\lambda) \mathbf{y})\\
=&g(\lambda \cdot 1 + (1-\lambda) \cdot 0)\\
\leq& \lambda g(1)  + (1-\lambda) g(0) \\
=& \lambda f(\mathbf{x}) + (1-\lambda) f(\mathbf{y}).
\end{aligned}
$$
**最后，利用上面的引理和一维情况的结果，可以证明多维情况，多维函数 $f:\mathbb{R}^n\rightarrow\mathbb{R}$ 是凸函数，当且仅当 $g(z) \stackrel{\mathrm{def}}{=} f(z \mathbf{x} + (1-z)  \mathbf{y})$ 是凸的，这里$z \in [0,1]$，$\mathbf{x}, \mathbf{y} \in \mathbb{R}^n$。根据一维情况，此条成立的条件为，当且仅当对于所有 $\mathbf{x}, \mathbf{y} \in \mathbb{R}^n$，$g'' = (\mathbf{x} - \mathbf{y})^\top \mathbf{H}(\mathbf{x} - \mathbf{y}) \geq 0$（$\mathbf{H} \stackrel{\mathrm{def}}{=} \nabla^2f$）这相当于根据半正定矩阵的定义，$\mathbf{H} \succeq 0$**



#### **詹森不等式**

**给定一个凸函数 $f$，最有用的数学工具之一就是詹森不等式，是凸性定义的一种推广**
$$
\sum_i \alpha_i f(x_i)  \geq f\left(\sum_i \alpha_i x_i\right) \text{ and } E_X[f(X)] \geq f\left(E_X[X]\right)
$$
**其中 $\alpha_i$ 是满足 $\sum_i \alpha_i = 1$ 的非负实数，$X$ 是随机变量，即凸函数的期望不小于期望的凸函数，其中后者通常是一个更简单的表达式**

**詹森不等式的一个常见应用，用一个较简单的表达式约束一个较复杂的表达式，可以应用于部分观察到的随机变量的对数似然。具体地，由于$\int P(Y) P(X \mid Y) dY = P(X)$，所以**
$$
E_{Y \sim P(Y)}[-\log P(X \mid Y)] \geq -\log P(X)
$$
**这里 $Y$是典型的未观察到的随机变量，$P(Y)$ 是它可能如何分布的最佳猜测，$P(X)$ 是将 $Y$ 积分后的分布。例如，在聚类中 $Y$ 可能是簇标签，而在应用簇标签时，$P(X \mid Y)$ 是生成模型**



#### **约束**

**凸优化的一个很好的特性是能够让我们有效地处理约束，即它使我们能够解决以下形式的约束优化问题**
$$
\begin{aligned} \mathop{\mathrm{minimize~}}_{\mathbf{x}} & f(\mathbf{x}) \\
    \text{ subject to } & c_i(\mathbf{x}) \leq 0 \text{ for all } i \in \{1, \ldots, N\}.
\end{aligned}
$$
**这里 $f$ 是目标函数，$c_i$ 是约束函数。例如第一个约束 $c_1(\mathbf{x}) = \|\mathbf{x}\|_2 - 1$，则参数 $\mathbf{x}$ 被限制为单位球。如果第二个约束 $c_2(\mathbf{x}) = \mathbf{v}^\top \mathbf{x} + b$，那么这对应于半空间上所有的 $\mathbf{x}$。同时满足这两个约束等于选择一个球的切片作为约束集**



##### **拉格朗日函数**	

**求解一个约束优化问题是困难的，解决这个问题的一种方法是使用拉格朗日函数 $L$，可以通过以下鞍点优化问题来表示，然后根据所讨论的实际问题的特性判断出哪些鞍点是所求的极值点**
$$
L(\mathbf{x}, \alpha_1, \ldots, \alpha_n) = f(\mathbf{x}) + \sum_{i=1}^n \alpha_i c_i(\mathbf{x}) \text{ where } \alpha_i \geq 0
$$
**这里的变量 $\alpha_i$（$i=1,\ldots,n$）是拉格朗日乘数它确保约束被正确地执行，选择合适的大小足以确保所有 $i$ 的 $c_i(\mathbf{x}) \leq 0$。例如，对于 $c_i(\mathbf{x}) < 0$ 中任意 $\mathbf{x}$，最终会选择 $\alpha_i = 0$。此外，这是一个鞍点优化问题。在这个问题中，想要使 $L$ 相对于 $\alpha_i$ 最大化，同时使它相对于 $\mathbf{x}$ 最小化，$L$ 的鞍点是原始约束优化问题的最优解**



##### **惩罚**

**求解拉格朗日函数 $L$ 是一种近似地满足约束优化问题的方法。除了满足 $c_i(\mathbf{x}) \leq 0$ 之外，我们只需将 $\alpha_i c_i(\mathbf{x})$ 添加到目标函数 $f(x)$。机器学习中一直在使用约束优化，比如，权重衰减，在目标函数中加入正则化项 $\frac{\lambda}{2} |\mathbf{w}|^2$，以确保 $\mathbf{w}$ 不会增长太大。可以看到，对于若干半径 $r$，这将确保 $|\mathbf{w}|^2 - r^2 \leq 0$。通过调整 $\lambda$ 的值，可以改变 $\mathbf{w}$ 的大小**

**目标函数 $f(x)$ 的复杂度、表达能力、丰富性或灵活性可以用 [*VCDimension*](https://en.wikipedia.org/wiki/Vapnik%E2%80%93Chervonenkis_dimension)（其值与参数量线性相关）度量。理论上，采样复杂性即优化目标函数需要的数据规模 $N$ 约等于 $10000*vcd$，这是一个比较宽松的上界，实际经验通常只需要 $N = 10*vcd$，为了减少需要的数据规模，就要降低 *VCDimension*，一种自然的思路就是降低参数的数量，比如，可以对参数施加约束让其变得稀疏，例如，正则化 $L_0$ 范数 $\|\mathbf{x}\|_0 \leq C$，表示的是 $\mathbf{x}$ 中非零元素的个数小于 $C$，但是这是一个 *NP* 问题，无法解。因此，只能松弛约束，不再严格要求部分参数 $\mathbf{x}$ 为 $0$ 而是希望尽可能接近于 $0$，即使用正则化 $L_1,L_2$ 范数被广泛的证明是可行的，能够实现相近似的效果**

**通常，给原问题添加惩罚是确保近似满足约束的一种好方法。在实践中证明虽然牺牲了一些精确但结果更满意更可靠**



##### **投影**

**满足约束条件的另一种策略是投影，同样，例如在处理梯度截断时，通过**
$$
\mathbf{g} \leftarrow \mathbf{g} \cdot \mathrm{min}(1, \theta/\|\mathbf{g}\|)
$$
**确保梯度的长度以 $\theta$ 为界限**

**这就是 $\mathbf{g}$ 在半径为 $\theta$ 的球上的投影，更泛化地说，在凸集 $\mathcal{X}$ 上的投影被定义为**
$$
\mathrm{Proj}_\mathcal{X}(\mathbf{x}) = \mathop{\mathrm{argmin}}_{\mathbf{x}' \in \mathcal{X}} \|\mathbf{x} - \mathbf{x}'\|
$$
**它是 $\mathcal{X}$ 中离 $\mathbf{X}$ 最近的点**

![Convex Projections.](./assets/%E6%88%91%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%BB%E7%BA%BF/projections.svg)

**投影的数学定义就如上，两个凸集，一个圆和一个菱形。两个集合内的点（黄色）在投影期间保持不变。两个集合（黑色）之外的点投影到集合中接近原始点（黑色）的点（红色）**



#### **小结**

* **凸集的交集都是凸的，其并集不都是凸的**
* **一个二次可微函数是凸函数，当且仅当其 $Hessian$ 矩阵是半正定的**
* **根据詹森不等式可知「一个多变量凸函数的总期望值」大于或等于「用每个变量的期望值计算这个函数的总值」**
* **凸约束可通过拉格朗日函数求解，只需在目标函数中加上一个惩罚就可以了，其中正则化可以降低 *VCDimension* **
* **投影映射到凸集中最接近原始点的点**



### **适定**

**大多数机器学习的问题都不是适定的，例如从最终数据中推断出先前温度分布的逆热方程不是适定的**

> *适定的 Hadamard 定义 1. 必然存在解；2. 解唯一；3. 解对输入有连续依赖（稳定性，通俗的理解就是当输入变化很小时，解不应该有太大变化）*

**不满足则为不适定（ill-posed problem）问题，正问题是适定的其反问题通常是不适定的，例如积分与求导，积分是正问题，求导是反问题。积分（给定初始条件）是适定性问题，求导是不适定问题**

**积分是求面积，某一点函数值它再大，由于 $\Delta S=y(x)\cdot\Delta x,\Delta x$ 非常小可以很好控制 $\Delta S$，因此 $S$ 的变化是很平滑的。而导数则不然，一旦函数值有阶跃或突变，求导的时除了无穷小量 $\Delta x$，很容易出现奇异值。可导是个很强的要求，连续次之，可积再次之，因此有可导必连续，连续必可积，反之则不然**

**问题是适定的，它仍然可能是病态的，不适定问题通常是病态的，通过合适的正则化约束可以将不适定问题转为适定问题，其目标函数一定是凸函数，因此，适定问题是想要的**

<img src="./assets/%E6%88%91%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%BB%E7%BA%BF/%E7%97%85%E6%80%81%E9%97%AE%E9%A2%98.png" alt="病态问题" style="zoom: 33%;" />



#### **病态**

**病态问题（ill-conditioned problem）是指输出结果相对于输入（自变量）非常敏感的问题，输入数据中哪怕是极少的噪声也会导致输出（因变量）的很大改变；相反的，对于输入不敏感的问题，称为良态问题**

**比如，以人体神经系统来说，身体健康的人的神经系统是良态的，在外界环境温度（输入）发生微小改变时，它对人体温度的调节（输出）也应该是微小的。再比如，一个良态的汽车动力系统，当系统输入即油门大小发生微小改变时，系统输出即动力的加减也应该是微小的**

**在机器学习中，一个分类/聚类/回归模型，当输入数据中存在噪声时，其输出与没有噪声时相比变化不大，则这个模型的鲁棒性就强，是良态的。一个存在过拟合的模型，因为泛化能力非常差，必然是病态的**



##### **条件数**

**[条件数](https://en.wikipedia.org/wiki/Condition_number)（condition-number）是问题的一个属性，表征输出相对于输入的微小变化而变化的快慢程度。用于衡量函数对输入中的变化或错误的敏感程度，以及输出中的错误有多少是由输入中的错误引起的。输入被轻微扰动而迅速改变的函数对于数值分析来说可能是有问题的，因为输入中的舍入误差（运算得到的近似值与精确值之间的差异，比如当用有限位数的浮点数来表示实数的时候就会产生舍入误差）可能导致输出的巨大变化**

**考虑函数 $f(x) = A^{−1} x$。当 $A ∈ R^{n×n}$ 具有特征值分解时，其条件数为**
$$
{max\atop{i,j}}  \frac{λi}{λj} 
$$
**实际是最大与最小特征值的模之比。条件数低的问题被称为条件良态问题，条件数高的问题被称为病态问题**

**例如一个线性方程组 $\pmb{W}x=y$**
$$
\pmb{W}=\left[
  \begin{array}
  &1333&−131\\
  331&-31
  \end{array}
  \right]
,
x=\left[
  \begin{array}
  &1\\
  11
  \end{array}
  \right]
$$
**可以解出**
$$
y=\left[
  \begin{array}
  &−120\\
  -13
  \end{array}
  \right]
    \\\\
  \frac{w1}{w2}=\left[
  \begin{array}
  &\frac{1333}{−131}\\
   \frac{331}{−31}
  \end{array}
  \right]
  =\left[
  \begin{array}
  &10.1756\\
   10.6774
  \end{array}
  \right]
$$
**其中矩阵 $\pmb{W}$ 的列之间的线性相关性非常高，即在各基向量方向变化很不均衡，如果对 $x$ 稍做调整，即使输入的微小改变，也引起了输出的大幅变动**
$$
\left\{
  \begin{array}{ll}   
  x_1=\left[
  \begin{array}
  &1.0097\\
  11.001
  \end{array}
  \right]\Longrightarrow
  y_1=\left[
  \begin{array}
  &−95.2\\
  −6.82
  \end{array}
  \right]\Longrightarrow
  \Delta y_1=\left[
  \begin{array}
  &20.67\%\\
	 47.54\%
  \end{array}
  \right]
  \\
  x_2=\left[
  \begin{array}
  &1.0024\\
	 11.010
  \end{array}
  \right]\Longrightarrow
  y_2=\left[
  \begin{array}
  &−106.11\\
	 −9.52
  \end{array}
  \right]\Longrightarrow
  \Delta y_2=\left[
  \begin{array}
  &11.58\%\\
	 26.92\%
  \end{array}
  \right]
  \end{array}
  \right.
$$
**通过 *Numpy* 内置的函数 `numpy.linalg.eig()` 求解 $\pmb{W}\xi=\lambda\xi$  得到特征向量及其特征值**
$$
\left\{
\begin{array}{ll}   
  
  \xi_1\approx\left[
  \begin{array}
  &0.97\\
   0.10
  \end{array}
  \right],
  \lambda_1\approx1300
\\  
  \xi_2\approx\left[
  \begin{array}
  &0.24\\
   1
  \end{array}
  \right],
  \lambda_2\approx1.57
  
\end{array}
\right.
$$
**特征向量表示的线性空间与原线性空间等价，可知输入 $x$ 发生变化则可反映在特征向量方向，因此，当矩阵的特征值差异过大时，即使输入沿着较大特征值的方向仅有微小的改变，也会导致最终的输出结果的较大改变**



#### **小结**

* **正则化约束可以将不适定问题转为适定问题，其目标函数是凸函数**
* **病态系统鲁棒性差，泛化性差，条件数可以反映是否病态**



### **梯度下降算法**

**梯度下降是机器学习的关键优化算法**



#### **一维梯度下降**

**连续可微实值函数 $f: \mathbb{R} \rightarrow \mathbb{R}$ 利用泰勒展开**
$$
f(x + \epsilon) = f(x) + \epsilon f'(x) + \mathcal{O}(\epsilon^2)
$$
**一阶近似 $f(x+\epsilon)$ 可通过 $x$ 处的函数值 $f(x)$ 和一阶导数 $f'(x)$ 得出。假设在负梯度方向上移动的 $\epsilon$ 会减少 $f$ 选择固定步长 $\eta > 0$ 然后取 $\epsilon = -\eta f'(x)$ 将其代入泰勒展开式可以得到**
$$
f(x - \eta f'(x)) = f(x) - \eta f'^2(x) + \mathcal{O}(\eta^2 f'^2(x))
$$
**$\eta f'^2(x)>0$ 梯度下降，如果导数 $f'(x) \neq 0$ 即梯度没有消失则可继续展开。此外总有 $\eta$ 小到足以使高阶项与结果不相关**
$$
f(x - \eta f'(x)) \lessapprox f(x)
$$
**意味着，如果使用**
$$
x \leftarrow x - \eta f'(x)
$$
**迭代 $x$，函数 $f(x)$ 的值可能会下降。因此，在梯度下降中，首先选择初始值 $x$ 和常数 $\eta > 0$，然后使用它们连续迭代 $x$，直到梯度 $|f'(x)|$ 的幅度足够小或迭代次数达到规定值**

**通过目标函数 $f(x)=x^2$ 实践梯度下降。求导可知 $x=0$ 时 $f(x)$ 取最小值，令 $x=10$ 作为初始值，设 $\eta=0.2$ 迭代 $10$ 次 $x$ 可以发现 $x$ 的值最终将接近最优解**

```python
# 目标函数
def f(x):  
    return x ** 2

# 目标函数的梯度
def f_grad(x):  
    return 2 * x
  
# 梯度下降
def gd(eta, f_grad):
    x = 10.0
    results = [x]
    for i in range(10):
        x -= eta * f_grad(x)
        results.append(float(x))
    print(f'epoch 10, x: {x:f}')
    return results

results = gd(0.2, f_grad)
```

![../_images/output_gd_79c039_27_0.svg](./assets/%E6%88%91%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%BB%E7%BA%BF/output_gd_79c039_27_0.svg)

**学习率 $\eta$ 决定目标函数能否收敛到局部最小值，以及何时收敛到最小值。如果学习率太小，将导致 $x$ 的更新非常缓慢，需要更多的迭代。在优化 $f(x)=x^2$ 问题中 $\eta = 0.05$ 尽管经过了 $10$ 次迭代，仍然离最优解很远**

![../_images/output_gd_79c039_42_1.svg](./assets/%E6%88%91%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%BB%E7%BA%BF/output_gd_79c039_42_1.svg)

**相反，如果学习率太大则 $\left|\eta f'(x)\right|$ 对 $f(x)$ 的一阶泰勒近似而言可能不够小，导致 $\mathcal{O}(\eta^2 f'^2(x))$ 不是可以忽略的无穷小项。此时 $x$ 的迭代不能保证降低 $f(x)$ 的值。当学习率为 $\eta=1.1$ 时，$x$ 跨过了最优解 $x=0$ 并逐渐发散**

![../_images/output_gd_79c039_54_1.svg](./assets/%E6%88%91%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%BB%E7%BA%BF/output_gd_79c039_54_1.svg)

**非凸函数的梯度下降，考虑函数 $f(x) = x \cdot \cos(cx)$，其中 $c$ 为常数。该函数有无穷多个局部最小值。根据选择的学习率，可能只会得到一个局部最小值且不切实际的高学习率可能导致较差的局部最小值**

![../_images/output_gd_79c039_66_1.svg](./assets/%E6%88%91%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%BB%E7%BA%BF/output_gd_79c039_66_1.svg)



#### **多元梯度下降**

**考虑 $\mathbf{x} = [x_1, x_2, \ldots, x_d]^\top$ 的情况，目标函数 $f: \mathbb{R}^d \to \mathbb{R}$ 将向量映射成标量，相应它的梯度也是多元的，是一个由 $d$ 个偏导数组成的向量**
$$
\nabla f(\mathbf{x}) = \bigg[\frac{\partial f(\mathbf{x})}{\partial x_1}, \frac{\partial f(\mathbf{x})}{\partial x_2}, \ldots, \frac{\partial f(\mathbf{x})}{\partial x_d}\bigg]^\top
$$
**梯度中的每个偏导数元素 $\partial f(\mathbf{x})/\partial x_i$ 代表了当输入 $x_i$ 时 $f$ 在 $\mathbf{x}$ 处的变化率，与单变量的情况一样，可以对多变量函数使用多元泰勒近似**
$$
f(\mathbf{x} + \boldsymbol{\epsilon}) = f(\mathbf{x}) + \mathbf{\boldsymbol{\epsilon}}^\top \nabla f(\mathbf{x}) + \mathcal{O}(|\boldsymbol{\epsilon}|^2)
$$
**在 $\boldsymbol{\epsilon}$ 的二阶项中，最陡下降的方向由负梯度 $-\nabla f(\mathbf{x})$ 得出，选择合适的学习率 $\eta > 0$ 实现梯度下降算法**
$$
\mathbf{x} \leftarrow \mathbf{x} - \eta \nabla f(\mathbf{x})
$$
**构造一个目标函数 $f(\mathbf{x})=x_1^2+2x_2^2$ 以二维向量 $\mathbf{x} = [x_1, x_2]^\top$ 作为输入，输出标量。梯度由$\nabla f(\mathbf{x}) = [2x_1, 4x_2]^\top$ 给出，从初始位置 $[-5, -2]$ 开始使用学习率 $\eta = 0.1$ 通过梯度下降优化，可以看到经过 $20$ 步之后，$\mathbf{x}$ 的值缓慢接近其最小值 $[0, 0]$**

```python
# 目标函数
def f_2d(x1, x2):  
    return x1 ** 2 + 2 * x2 ** 2

# 目标函数的梯度
def f_2d_grad(x1, x2):  
    return (2 * x1, 4 * x2)

# 梯度下降
def gd_2d(x1, x2, s1, s2, f_grad, eta=0.1):
    g1, g2 = f_grad(x1, x2)
    return (x1 - eta * g1, x2 - eta * g2, 0, 0)
```

![../_images/output_gd_79c039_90_1.svg](./assets/%E6%88%91%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%BB%E7%BA%BF/output_gd_79c039_90_1.svg)



#### **自适应方法**

**选择恰到好处的学习率 $\eta$ 很棘手。如果把它选得太小优化太慢，如果太大则会振荡，甚至可能发散。如果有可以自动确定 $\eta$ 或者完全不必选择学习率的方法就会方便很多，这种方法是二阶的，除了考虑目标函数的值和梯度、还需要考虑它的曲率等，计算代价较大**



##### **牛顿法**

**事实上函数 $f: \mathbb{R}^d \rightarrow \mathbb{R}$ 的泰勒展开式可以进一步写成**
$$
f(\mathbf{x} + \boldsymbol{\epsilon}) = f(\mathbf{x}) + \boldsymbol{\epsilon}^\top \nabla f(\mathbf{x}) + \frac{1}{2} \boldsymbol{\epsilon}^\top \nabla^2 f(\mathbf{x}) \boldsymbol{\epsilon} + \mathcal{O}(|\boldsymbol{\epsilon}|^3)
$$
**将 $\mathbf{H} \stackrel{\mathrm{def}}{=} \nabla^2 f(\mathbf{x})$ 定义为 $f$ 的 $Hessian$ 是 $d \times d$ 矩阵 $\mathbf{H}$ 即多元函数的二阶偏导数。当 $d$ 很小且问题简单时 $\mathbf{H}$ 容易计算，但是对于深度神经网络而言 $\mathbf{H}$ 一般非常大很难计算， $\mathcal{O}(d^2)$ 的存储代价也会很高，且通过反向传播进行计算更是雪上加霜，忽略这些考量与高阶项，取函数对 $\boldsymbol{\epsilon}$ 的导数得**
$$
\nabla f(\mathbf{x}) + \mathbf{H} \boldsymbol{\epsilon} = 0 \text{ and hence } \boldsymbol{\epsilon} = -\mathbf{H}^{-1} \nabla f(\mathbf{x})\\
\mathbf{x} \leftarrow \mathbf{x} - \mathbf{H}^{-1} \nabla f(\mathbf{x})
$$
**解优化问题需要将 $Hessian$ 矩阵 $\mathbf{H}$ 求逆。例如 $f(x) = \frac{1}{2} x^2$ 泰勒展开式为 $f(x+\epsilon)= \frac{1}{2} x^2 + \epsilon x + \frac{1}{2} \epsilon^2$ 有 $\nabla f(x) = x$ 和 $\mathbf{H} = 1$。对于任何 $x$ 可得 $\epsilon = -x$ 而 $f$ 的最小值满足 $\nabla f = 0$，此时优化一步就完美地收敛了。对于凸双曲余弦函数 $cosh(cx)$ 其中 $c$ 为常数，经过几次迭代后，得到了 $x=0$ 处的全局最小值**

```python
# 目标函数
def f(x，c=0.5):  
    return torch.cosh(c * x)

# 目标函数的梯度	
def f_grad(x):  
    return c * torch.sinh(c * x)

# 目标函数的Hessian
def f_hessian(x):  
    return c**2 * torch.cosh(c * x)

# 牛顿法
def nt(eta=1):
    x = 10.0
    results = [x]
    for i in range(10):
        x -= eta * f_grad(x) / f_hess(x)
        results.append(float(x))
    return results
```

![../_images/output_gd_79c039_102_1.svg](./assets/%E6%88%91%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%BB%E7%BA%BF/output_gd_79c039_102_1.svg)

**考虑非凸函数，如 $f(x) = x \cos(c x)$ 其中 $c$ 为常数。如果 $Hessian$ 矩阵非正定即二阶导数是负的 $f$ 的值可能会趋于增加**

```python
# 目标函数
def f(x, c=0.15*np.pi):  
    return x * torch.cos(c * x)
  
# 目标函数的梯度
def f_grad(x):  
    return torch.cos(c * x) - c * x * torch.sin(c * x)

# 目标函数的Hessian
def f_hessian(x):  
    return - 2 * c * torch.sin(c * x) - x * c**2 * torch.cos(c * x)
```

![../_images/output_gd_79c039_114_1.svg](./assets/%E6%88%91%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%BB%E7%BA%BF/output_gd_79c039_114_1.svg)

**可以通过取 $Hessian$ 的绝对值修正或重新引入学习率。虽然违背了牛顿法的初衷，但因为有二阶信息使曲率较大时保持优化缓慢，而在目标函数较平坦时则优化迅速**

![../_images/output_gd_79c039_126_1.svg](./assets/%E6%88%91%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%BB%E7%BA%BF/output_gd_79c039_126_1.svg)



##### **收敛性分析**

**以凸函数 $f$ 为例，分析牛顿法收敛速度。目标凸函数三次可微，而且二阶导数不为零，即 $f'' > 0$** 

**用 $x^{(k)}$ 表示 $x$ 在第 $k^\mathrm{th}$ 次迭代时的值，令 $e^{(k)} \stackrel{\mathrm{def}}{=} x^{(k)} - x^*$ 表示 $k^\mathrm{th}$ 迭代时与最优值的距离。通过泰勒展开得条件 $f'(x^*) = 0$ 可以写成**
$$
0 = f'(x^{(k)} - e^{(k)}) = f'(x^{(k)}) - e^{(k)} f''(x^{(k)}) + \frac{1}{2} (e^{(k)})^2 f'''(\xi^{(k)})
$$
**对于 $\xi^{(k)} \in [x^{(k)} - e^{(k)}, x^{(k)}]$ 成立。将上述展开除以 $f''(x^{(k)})$ 得到**
$$
e^{(k)} - \frac{f'(x^{(k)})}{f''(x^{(k)})} = \frac{1}{2} (e^{(k)})^2 \frac{f'''(\xi^{(k)})}{f''(x^{(k)})}
$$
**在牛顿法中 $x^{(k+1)} = x^{(k)} - f'(x^{(k)}) / f''(x^{(k)})$。代入更新方程，取两边的绝对值得到**
$$
\left|e^{(k+1)}\right| = \frac{1}{2}(e^{(k)})^2 \frac{\left|f'''(\xi^{(k)})\right|}{f''(x^{(k)})}
$$
**因此，每当处于有界区域 $\left|f'''(\xi^{(k)})\right| / (2f''(x^{(k)})) \leq c$， 就有一个二次递减误差**
$$
\left|e^{(k+1)}\right| \leq c (e^{(k)})^2
$$
**称之为线性收敛，而将 $\left|e^{(k+1)}\right| \leq \alpha \left|e^{(k)}\right|$ 这样的条件称为恒定收敛速度。虽然无法估计整体收敛的速度，但是一旦接近极小值，收敛将变得非常快。另外，这种分析要求 $f$ 在高阶导数上表现良好，即确保 $f$ 值的变化过程没有超常的特性**



##### **梯度预处理**

**计算和存储完整的 $Hessian$ 非常昂贵，可以避免计算整个 $Hessian$，而只计算对角线项用来进行梯度预处理**
$$
\mathbf{x} \leftarrow \mathbf{x} - \eta \mathrm{diag}(\mathbf{H})^{-1} \nabla f(\mathbf{x})
$$
**数据的预处理中若一个变量以毫米表示高度，另一个变量以公里表示高度，假设这两种自然尺度都以米为单位，那么参数化后就出现了严重的不匹配，使用预处理如归一化操作有利于优化。梯度下降过程中乘 $Hessian$ 对角项相当于为每个变量的梯度选择了不同的学习率**



##### **线搜索**

**梯度下降的一个关键问题是可能会优化过冲或不足，解决这一问题的简单方法是在梯度下降中结合线搜索。通过 $\nabla f(\mathbf{x})$ 给出的方向，然后进行二分搜索，以确定哪个学习率 $\eta$ 使 $f(\mathbf{x} - \eta \nabla f(\mathbf{x}))$ 取最小值，虽然收敛迅速但是线搜索的每一步都需要评估整个数据集上的目标函数，实现方式代价太高**



#### **随机梯度下降**

**机器学习的数据量庞大，直接使用梯度下降计算代价较大，因此使用随机梯度下降替代**



##### **随机梯度更新**

**在深度学习中，目标函数通常是训练数据集中每个样本的损失函数的平均值。给定 $n$ 个样本的训练数据集，我们假设 $f_i(\mathbf{x})$ 是关于索引 $i$ 的训练样本的损失函数，其中 $\mathbf{x}$ 是参数向量，可得目标函数**
$$
f(\mathbf{x}) = \frac{1}{n} \sum_{i = 1}^n f_i(\mathbf{x})
$$
**$\mathbf{x}$ 的目标函数的梯度计算为**
$$
\nabla f(\mathbf{x}) = \frac{1}{n} \sum_{i = 1}^n \nabla f_i(\mathbf{x})
$$
**如果使用梯度下降法，则每个自变量迭代的计算代价为 $\mathcal{O}(n)$ 随 $n$ 线性增长。当训练数据集较大时，每次迭代的梯度下降计算代价将较高**

**随机梯度下降可降低每次迭代时的计算代价。在随机梯度下降的每次迭代中，我们对数据样本随机均匀采样一个索引 $i$，其中 $i\in{1,\ldots, n}$，并计算梯度 $\nabla f_i(\mathbf{x})$ 以更新 $\mathbf{x}$**
$$
\mathbf{x} \leftarrow \mathbf{x} - \eta \nabla f_i(\mathbf{x})
$$
**其中 $\eta$ 是学习率，每次迭代的计算代价从梯度下降的 $\mathcal{O}(n)$ 降至常数 $\mathcal{O}(1)$。随机梯度 $\nabla f_i(\mathbf{x})$ 是对完整梯度$\nabla f(\mathbf{x})$ 的无偏估计**
$$
\mathbb{E}_i \nabla f_i(\mathbf{x}) = \frac{1}{n} \sum_{i = 1}^n \nabla f_i(\mathbf{x}) = \nabla f(\mathbf{x})
$$
**平均而言，随机梯度是对梯度的良好估计，随机梯度下降可认为是向梯度添加均值为 $0$、方差为 $1$ 的随机噪声的梯度下降**

```python
# 目标函数
def f(x1, x2):  
    return x1 ** 2 + 2 * x2 ** 2

# 目标函数的梯度
def f_grad(x1, x2):  
    return 2 * x1, 4 * x2

def sgd(x1, x2, s1, s2, f_grad, eta=0.1, lr=1):
    g1, g2 = f_grad(x1, x2)
    # 模拟有噪声的梯度
    g1 += torch.normal(0.0, 1, (1,))
    g2 += torch.normal(0.0, 1, (1,))
    eta_t = eta * lr()
    return (x1 - eta_t * g1, x2 - eta_t * g2, 0, 0)
```

![../_images/output_sgd_baca77_18_1.svg](./assets/%E6%88%91%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%BB%E7%BA%BF/output_sgd_baca77_18_1.svg)

**随机梯度下降中变量的轨迹比梯度下降中观察到的轨迹嘈杂得多。由于梯度的随机性质，即使接近最小值仍然受到通过 $\eta \nabla f_i(\mathbf{x})$ 的瞬间梯度所注入的不确定性的影响。经过 $50$ 次迭代，结果仍然不那么好。并且经过额外的步骤也不会得到改善**

**因此唯一的选择就只能改变学习率 $\eta$，但如果选择的学习率太小或太大都不合适，解决这些相互冲突的目标的唯一方法是在优化过程中动态降低学习率，用与时间相关的学习率 $\eta(t)$ 取代 $\eta$ 增加了控制优化算法收敛的复杂性。需要注意 $\eta$ 的衰减速度，如果太快将过早停止优化。如果太慢优化将花费太多时间，随着时间推移调整 $\eta$ 的一些基本策略是**
$$
\begin{aligned} \eta(t) & = \eta_i \;\text{ if } \;t_i \leq t \leq t_{i+1} && \text{分段常数} \\ \eta(t) & = \eta_0 \cdot e^{-\lambda t} && \text{指数衰减} \\ \eta(t) & = \eta_0 \cdot (\beta t + 1)^{-\alpha} && \text{多项式衰减} 
\end{aligned}
$$
**分段常数是训练深度网络的常见策略。或者通过指数衰减更积极地减低它，往往会导致算法收敛之前过早停止。受欢迎的选择是 $\alpha = 0.5$ 的多项式衰减。在凸优化的情况下，有许多证据表明表现良好**

**使用指数衰减**

```python
def exponential_lr():
    global t
    t += 1
    return math.exp(-0.1 * t)

t = 1
lr = exponential_lr
```

![../_images/output_sgd_baca77_30_1.svg](./assets/%E6%88%91%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%BB%E7%BA%BF/output_sgd_baca77_30_1.svg)

**参数的方差大大减少。但是很难收敛到最优解 $\mathbf{x} = (0, 0)$ 即使经过 $1000$ 个迭代步骤，仍然离最优解很远。事实上，该算法根本无法收敛。使用多项式衰减，其中学习率随迭代次数的平方根倒数衰减，那么仅在 $50$ 次迭代之后，收敛就会更好**

```python
def polynomial_lr():
    global t
    t += 1
    return (1 + 0.1 * t) ** (-0.5)

t = 1
lr = polynomial_lr
```

![../_images/output_sgd_baca77_42_1.svg](./assets/%E6%88%91%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%BB%E7%BA%BF/output_sgd_baca77_42_1.svg)

**另外，还可以从较小的学习率开始，然后使其迅速上涨，再让它降低，尽管这会更慢。甚至可以在较小和较大的学习率之间切换**



##### **收敛性分析**

**假设所有 $\boldsymbol{\xi}$ 的目标函数 $f(\boldsymbol{\xi}, \mathbf{x})$ 在 $\mathbf{x}$ 中都是凸的，考虑随机梯度下降更新**
$$
\tag{1}
\mathbf{x}_{t+1} = \mathbf{x}_{t} - \eta_t \partial_\mathbf{x} f(\boldsymbol{\xi}_t, \mathbf{x})
$$
**其中 $f(\boldsymbol{\xi}_t, \mathbf{x})$ 是训练样本 $f(\boldsymbol{\xi}_t, \mathbf{x})$ 的目标函数 $\boldsymbol{\xi}_t$ 从第 $t$ 步的某个分布中提取，$\mathbf{x}$ 是模型参数，用 $R(\mathbf{x}) = E_{\boldsymbol{\xi}}[f(\boldsymbol{\xi}, \mathbf{x})]$ 表示期望风险，$R^*$ 表示对于 $\mathbf{x}$ 的最低风险。最后让 $\mathbf{x}^*$ 表示最小值（我们假设它存在于定义 $\mathbf{x}$ 的域中）在这种情况下，可以跟踪时间 $t$ 处的当前参数 $\mathbf{x}_t$ 和风险最小化器 $\mathbf{x}^*$ 之间的距离，观察是否随着时间的推移而改善**
$$
\tag{2}
\begin{aligned} 
&|\mathbf{x}_{t+1} - \mathbf{x}^*|^2 \\
=& |\mathbf{x}_{t} - \eta_t \partial_\mathbf{x} f(\boldsymbol{\xi}_t, \mathbf{x}) - \mathbf{x}^*|^2 \\
=& |\mathbf{x}_{t} - \mathbf{x}^*|^2 + \eta_t^2 |\partial_\mathbf{x} f(\boldsymbol{\xi}_t, \mathbf{x})|^2 - 2 \eta_t \left\langle \mathbf{x}_t - \mathbf{x}^*, \partial_\mathbf{x} f(\boldsymbol{\xi}_t, \mathbf{x})\right\rangle.
\end{aligned}
$$
**假设随机梯度 $\partial_\mathbf{x} f(\boldsymbol{\xi}_t, \mathbf{x})$ 的 $L_2$ 范数受到常数 $L$ 的限制，因此**
$$
\tag{3}
\eta_t^2 |\partial_\mathbf{x} f(\boldsymbol{\xi}_t, \mathbf{x})|^2 \leq \eta_t^2 L^2
$$
**对于 $\mathbf{x}_t$ 和 $\mathbf{x}^*$ 之间的距离如何变化的期望。事实上，对于任何具体的步骤序列，距离可能会增加，这取决于 $\boldsymbol{\xi}_t$ 因此需要点积的边界。因为对于任何凸函数 $f$，所有 $\mathbf{x}$ 和 $\mathbf{y}$ 都满足 $f(\mathbf{y}) \geq f(\mathbf{x}) + \langle f'(\mathbf{x}), \mathbf{y} - \mathbf{x} \rangle$，按凸性有**
$$
\tag{4}
f(\boldsymbol{\xi}_t, \mathbf{x}^*) \geq f(\boldsymbol{\xi}_t, \mathbf{x}_t) + \left\langle \mathbf{x}^* - \mathbf{x}_t, \partial_{\mathbf{x}} f(\boldsymbol{\xi}_t, \mathbf{x}_t) \right\rangle
$$
**根据 $(2),(3),(4)$ 在时间 $t+1$ 时获得参数之间距离的边界**
$$
\tag{5}
|\mathbf{x}_{t} - \mathbf{x}^*|^2 - |\mathbf{x}*{t+1} - \mathbf{x}^*|^2 \geq 2 \eta_t (f(\boldsymbol{\xi}_t, \mathbf{x}_t) - f(\boldsymbol{\xi}_t, \mathbf{x}^*)) - \eta_t^2 L^2
$$
**这意味着，只要当前损失和最优损失之间的差异超过 $\eta_t L^2/2$，我们就会取得进展。由于这种差异必然会收敛到零，因此学习率 $\eta_t$ 也需要消失，根据 $(5)$ 取期望得**
$$
\tag{6}
E\left[|\mathbf{x}_{t} - \mathbf{x}^*|^2\right] - E\left[|\mathbf{x}_{t+1} - \mathbf{x}^*|^2\right] \geq 2 \eta_t [E[R(\mathbf{x}_t)] - R^*] - \eta_t^2 L^2
$$
**最后一步是对 $t \in {1, \ldots, T}$ 的不等式求和。在求和过程中抵消中间项，然后舍去低阶项，可得**
$$
\tag{7}
|\mathbf{x}_1 - \mathbf{x}^*|^2 \geq 2 \left (\sum_{t=1}^T \eta_t \right) [E[R(\mathbf{x}_t)] - R^*] - L^2 \sum_{t=1}^T \eta_t^2
$$
**利用了给定的 $\mathbf{x}_1$，因而可以去掉期望，最后定义**
$$
\tag{8}
\bar{\mathbf{x}} \stackrel{\mathrm{def}}{=} \frac{\sum_{t=1}^T \eta_t \mathbf{x}_t}{\sum_{t=1}^T \eta_t}
$$
**因为有**
$$
\tag{9}
E\left(\frac{\sum_{t=1}^T \eta_t R(\mathbf{x}_t)}{\sum_{t=1}^T \eta_t}\right) = \frac{\sum_{t=1}^T \eta_t E[R(\mathbf{x}_t)]}{\sum_{t=1}^T \eta_t} = E[R(\mathbf{x}_t)]
$$
**根据詹森不等式中（$i=t$，$\alpha_i = \eta_t/\sum_{t=1}^T \eta_t$）和 $R$ 的凸性使其满足的 $E[R(\mathbf{x}_t)] \geq E[R(\bar{\mathbf{x}})]$，因此**
$$
\tag{10}
\sum_{t=1}^T \eta_t E[R(\mathbf{x}_t)] \geq \sum_{t=1}^T \eta_t E\left[R(\bar{\mathbf{x}})\right]
$$
**将其代入不等式 $(7)$ 得到边界**
$$
\tag{11}
\left[E[\bar{\mathbf{x}}]\right] - R^* \leq \frac{r^2 + L^2 \sum_{t=1}^T \eta_t^2}{2 \sum_{t=1}^T \eta_t}
$$
**其中 $r^2 \stackrel{\mathrm{def}}{=} |\mathbf{x}_1 - \mathbf{x}^*|^2$ 是初始选择参数与最终结果之间距离的边界。简而言之，收敛速度取决于随机梯度标准的限制方式 $L$ 以及初始参数值与最优结果的距离 $r$ 。请注意，边界由 $\bar{\mathbf{x}}$ 而不是 $\mathbf{x}_T$ 表示。因为 $\bar{\mathbf{x}}$ 是优化路径的平滑版本。只要知道 $r, L$ 和 $T$，就可以选择学习率 $\eta = r/(L \sqrt{T})$。这个就是上界 $rL/\sqrt{T}$，也就是说将按照速度 $\mathcal{O}(1/\sqrt{T})$ 收敛到最优解**



#### **小批量随机梯度下降**

**基于梯度的学习方法中梯度下降中使用完整数据集来计算梯度并更新参数，随机梯度下降中一次处理一个训练样本更新参数。二者各有利弊，每当数据非常相似时，梯度下降并不是非常数据高效。而由于 $CPU$ 和 $GPU$ 无法充分利用向量化，随机梯度下降并不特别计算高效，小批量随机梯度下降则是两者的折中方案**



##### **向量化和缓存**

**使用小批量的决策的核心是计算效率。当考虑与多个 $GPU$ 和多台服务器并行处理时，我们需要向每个 $GPU$ 发送至少一张图像。有了每台服务器 $8$ 个 $GPU$ 和 $16$ 台服务器，就能得到大小为 $128$ 的小批量**

**当只有单个 $GPU$ 甚至 $CPU$ 时，事情会更微妙一些，这些设备有多种类型的内存，此时需要考虑多种类型的计算单元以及在它们之间不同的带宽限制。例如，一个 $CPU$ 有少量寄存器，$L1$ 和 $L2$ 缓存，以及 $L3$ 缓存（在不同的处理器内核之间共享）随着缓存的大小的增加，延迟也在增加，同时带宽在减少，而处理器能够执行的操作远比主内存接口所能提供的多得多**

**首先，具有 $16$ 个内核和 $\text{AVX-512}$ 向量化的 $2GHz\;CPU$ 每秒可处理高达 $2 \cdot 10^9 \cdot 16 \cdot 32 = 10^{12}$ 个字节。$GPU$ 的性能一般是该数值的 $100$ 倍。而另一方面，中端服务器处理器的带宽可能不超过 $100Gb/s$ 即不到处理器满负荷所需的十分之一。且并非所有的内存入口都是相等的，内存接口通常为 $64$ 位或更宽，因此读取单个字节会导致由于更宽的存取而产生的代价，其次，第一次存取的额外开销很大，而按序存取或突发读取相对开销较小**

**减轻这些限制的方法是使用足够快的 $CPU$ 缓存层次结构来为处理器提供数据。例如，矩阵-矩阵乘法 $\mathbf{A} = \mathbf{B}\mathbf{C}$ 有很多方法来计算 $\mathbf{A}$**

1. **可以通过点积进行逐元素计算 $\mathbf{A}_{ij} = \mathbf{B}_{i,:} \mathbf{C}_{:,j}^\top$，每次计算一个元素$\mathbf{A}_{ij}$ 时，都需要将一行和一列向量复制到 $CPU$ 中。由于矩阵元素是按顺序对齐的，因此当从内存中读取时，需要访问两个向量中许多不相交的位置，访问速度低**
2. **可以一次计算一列计算 $\mathbf{A}_{:,j} = \mathbf{B} \mathbf{C}_{:,j}^\top$，同样也可以一次计算$\mathbf{A}$一行$\mathbf{A}_{i,:}$，相对更有利，能够在遍历 $\mathbf{B}$ 的同时，将列向量 $\mathbf{C}_{:,j}$ 保留在 $CPU$ 缓存中，内存带宽需求减半，相应地提高了访问速度**
3. **可以直接计算$\mathbf{A} = \mathbf{B} \mathbf{C}$，表面上是最可取的，然而大多数矩阵可能不能完全放入缓存中**
4. **可以将 $\mathbf{B}$ 和 $\mathbf{C}$ 分成较小的区块矩阵，然后一次计算 $\mathbf{A}$ 的一个区块，实践上有用的方案，可以将矩阵的区块移到缓存中然后在本地将它们相乘**

**除此之外，编程语言和学习框架本身带来的额外开销也是相当大**



##### **小批量**

**处理单个观测值需要执行许多单一矩阵-矢量（甚至矢量-矢量）乘法，执行 $\mathbf{w} \leftarrow \mathbf{w} - \eta_t \mathbf{g}_t$ 时消耗大，其中**
$$
\mathbf{g}_t = \partial_{\mathbf{w}} f(\mathbf{x}_{t}, \mathbf{w})
$$
**通过将其应用于一个小批量观测值来提高此操作的计算效率，将梯度 $\mathbf{g}_t$ 替换为一个小批量而不是单个观测值**
$$
\mathbf{g}_t = \partial_{\mathbf{w}} \frac{1}{|\mathcal{B}_t|} \sum_{i \in \mathcal{B}_t} f(\mathbf{x}_{i}, \mathbf{w})
$$
**这对 $\mathbf{g}_t$ 的统计属性有什么影响，由于 $\mathbf{x}_t$ 和小批量 $\mathcal{B}_t$ 的所有元素都是从训练集中随机抽出的，因此梯度的期望保持不变。另一方面，方差显著降低。由于小批量梯度由正在被平均计算的 $b := |\mathcal{B}_t|$ 个独立梯度组成，其标准差降低了 $b^{-\frac{1}{2}}$。这本身是一件好事，因为这意味着更新与完整的梯度更接近了**

**直观来说，这表明选择大型的小批量 $\mathcal{B}_t$ 将是普遍可行的。然而与计算代价的线性增长相比，标准差的额外减少是微乎其微的。在实践中选择一个足够大的小批量匹配 $CPU$ 与 $GPU$ 的内存即可**



#### **小结**

- **学习率的大小很重要，学习率太大会使模型发散，学习率太小会优化不足**
- **梯度下降会可能陷入局部极小值，而得不到全局最小值**
- **在高维模型中，调整学习率是很复杂的，可以使用 $Hessian$ 矩阵的对角进行预处理，调节学习率比例**
- **牛顿法在凸问题中一旦开始正常工作，速度就会快得多，但对于非凸问题，不要不作任何调整就使用牛顿法**

- **对于凸问题，可以证明选择合适范围内的学习率，随机梯度下降将收敛到最优解**
- **如果学习率太小或太大都会出现问题，通常只有经过多次实验后才能找到合适的学习率**
- **当训练数据集中有大量样本时，随机梯度下降的每次迭代的代价更低**
- **随机梯度下降在非凸情况下一般不可用，但是其梯度中一定程度的噪声可能会使参数跳出局部最小值**

- **由于减少了学习框架的额外开销，使用更好的内存定位以及 $CPU$ 和 $GPU$ 上的缓存，向量化使代码更加高效**
- **随机梯度下降的统计效率与梯度下降一次处理数据的计算效率之间存在权衡，小批量随机梯度下降提供了均衡的方案**
- **一般来说，在训练期间降低学习率有助于训练，小批量随机梯度下降比随机梯度下降和梯度下降的优化速度快，收敛风险小**
- **理论上，确定数据集与优化目标后，连接两者的真实模型也自然确定了，此时无法直接确定真实模型，因此，选择契合优化目标的损失函数，通过梯度下降优化一般模型使其尽可能的拟合真实模型是行之有效**

 

### **启发式算法**

#### 退火算法

#### 粒子群算法

#### 遗传算法

#### 蚁群算法





## **拓展**

### **深度学习**

### **广度学习**

